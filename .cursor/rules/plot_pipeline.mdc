---
globs: salk_toolkit/pp.py, salk_toolkit/plots.py, salk_toolkit/validation.py, tests/test_plots.py, salk_toolkit/tools/explorer.py, tests/test_pp.py
---
# Plot Pipeline

## Mission statement
- Standardize basic faceting, filtering and aggregation syntax to efficiently draw standard plots on large annotated datasets.
- If needed, more context on data annotations is at [data_annotations.mdc](mdc:.cursor/rules/data_annotations.mdc)

## Organization
- Pipeline orchestration lives in `salk_toolkit/pp.py`
- Plot implementations live in `salk_toolkit/plots.py`
- Descriptor/validation models live in `salk_toolkit/validation.py`

## Pipeline flow (`e2e_plot`)
- Plot suitability (`matching_plots`)
  - Determine if the chosen plot is suitable to display the selected data
  - This is done based on the data and it's annotations
- Data transformation (`pp_transform_data` and `wrangle_data`)
  - Lazy open data source with polars and parse data annotations
  - Do all the filtering and unpivoting required
  - Do the aggregation required for the specific plot 
  - Return pandas dataframe of aggregated data + all metadata generated in the process as `pparams` object
- Plot creation (`create_plot`)
  - Handle all the boilerplate with tooltips, colors, translations common for all plots
  - Call the function for the specific plot 
  - Return either a plot or a matrix (list-of-list) of plots, depending on request

## Plot Descriptor (`pp_desc`)
- Schema in `salk_toolkit/validation.py` (`PlotDescriptor` pydantic model)
- `impute_factor_cols` backfills sensible `factor_cols`; `matching_plots` rejects descriptors when metadata requirements (e.g. ordered facets) aren't met—check its messages before forcing a plot.

## Plot registration (`stk_plot` decorator factory)
- All available plot functions are kept in a plot registry dictionary `registry`
- Registration happens when defining a function with the `stk_plot` decorator factory
- Paramters to `stk_plot` serve as metadata to tell the pipeline what the plot requires/expects from inputs
  - That metadata is used to find matching plot types and prioritize them with `matching_plots`
  - Prioretization is mainly for quick exploratory data analysis in salk_toolkit/explorer.py
- Plot functions consume the `pparams` dictionary created by `pp_transform_data` and augmented in `create_plot`
  - Contains the data, tooltips, colors, column orders, ...

## Data Preparation (`pp_transform_data`, `wrangle_data`)
- Operates on Polars `LazyFrame` for performance
  - This is by necessity as data is often millions of rows and pandas would be too slow. 
  - Do not convert anything to pandas in these functions unless it is very heavily aggregated to only a few values
- Automatically guarantees a weight column (`weight_col`) and fills missing weights with `1.0`.
- Handles filter dictionaries via `pp_filter_data_lz`, allowing categorical selections, range filters (`[None, min, max]`), and group aliasing.
- Numeric factors are discretised with quantile cuts or explicit breaks (see `discretize_continuous`); metadata is updated to keep category order.
- Categoricals can be converted to continuous (`convert_res='continuous'`) by mapping ordered categories to numeric scales (`num_values` or inferred 0..n).
- Supports bootstrap-like draws: merges deterministic draws from `data_meta['draws_data']` or computes stable draws with `stable_draws`.
- Multi-question groups (`group_columns_dict`) are unpivoted to long form (`question` column) before aggregation
- Aggregation happens in `wrangle_data`

## Development Tips
- Pipeline is built assuming the Altair plotting library (which is a wrapper for Vega Lite)
- We are locked on polars==1.27.1 to use the old streaming engine, as the new engine does not stream `unpivot` and it is critical. 
- Keep descriptor mutations local—`e2e_plot` copies the input dict, but downstream code may assume ownership of nested structures.
- When adding new plot metadata flags, update both `matching_plots` and `calculate_priority` so auto-selection keeps working.
- Any new column-level requirements should extend the metadata extracted by `update_data_meta_with_pp_desc` to keep dashboards and filters in sync.
- Edit the `.py` modules directly and capture context via docstrings/section comments.

## Testing 
- `tests/test_plots.py` - e2e tests
  - `_run_plot_test` renders the chart and compares normalised Altair JSON to reference files stored in `tests/reference_plots`
    - Use `pytest --recompute` to refresh references after intentional visual changes.
    - Always confirm that only the tests for that plot fail before calling recompute
  - When adding plot types, create a new e2e test
  - When adding options to PlotDescriptor, also make sure they are added to at least one e2e test
- `tests/test_pp.py` - unit tests
  - unit test all new sub-functions


