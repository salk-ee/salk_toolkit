{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots\n",
    "> Common plots used in the dashboards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "import json, os, math\n",
    "import itertools as it\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "\n",
    "from typing import List, Tuple, Dict, Union, Optional\n",
    "\n",
    "import altair as alt\n",
    "import scipy as sp\n",
    "import scipy.stats as sps\n",
    "from scipy.cluster import hierarchy\n",
    "from KDEpy import FFTKDE\n",
    "from KDEpy.bw_selection import *\n",
    "import arviz as az\n",
    "\n",
    "from salk_toolkit.utils import *\n",
    "from salk_toolkit.io import extract_column_meta, read_json\n",
    "from salk_toolkit.pp import registry, registry_meta, e2e_plot, stk_plot\n",
    "\n",
    "from matplotlib import font_manager\n",
    "from PIL import ImageFont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For tests, set up a data file and import from pp\n",
    "data_file = '../samples/w25_bootstrap.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.data_transformers.disable_max_rows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility function to wrap horizontal legends properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "\n",
    "# Find a sensible approximation to the font used in vega/altair\n",
    "font = font_manager.FontProperties(family='sans-serif', weight='regular')\n",
    "font_file = font_manager.findfont(font)\n",
    "legend_font = ImageFont.truetype(font_file,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "# Legends are not wrapped, nor is there a good way of doing accurately it in vega/altair\n",
    "# This attempts to estimate a reasonable value for columns which induces wrapping\n",
    "def estimate_legend_columns_horiz_naive(cats, width):\n",
    "    max_str_len = max(map(len,cats))\n",
    "    n_cols = max(1,width//(15+5*max_str_len))\n",
    "    # distribute them roughly equally to avoid last row being awkwardly shorter\n",
    "    n_rows = int(math.ceil(len(cats)/n_cols))\n",
    "    return int(math.ceil(len(cats)/n_rows))\n",
    "\n",
    "# More sophisticated version that looks at lengths of individual strings across multiple rows\n",
    "# ToDo: it should max over each column separately not just look at max(sum(row)). This is close enough though.\n",
    "def estimate_legend_columns_horiz(cats, width, extra_text=[]):\n",
    "    \n",
    "    max_cols, restart = len(cats), True\n",
    "    if extra_text: width -= max(map(legend_font.getlength,extra_text))\n",
    "    lens = list(map(lambda s: 25+legend_font.getlength(s),cats))\n",
    "    while restart:\n",
    "        restart, rl, cc = False, 0, 0\n",
    "        for l in lens:\n",
    "            if cc >= max_cols: # Start a new row\n",
    "                rl, cc = l, 1\n",
    "            elif rl + l > width: # Exceed width - restart\n",
    "                max_cols = cc\n",
    "                # Start from beginning every thime columns number changes\n",
    "                # This is because what ends up in second+ rows depends on length of first\n",
    "                restart = True\n",
    "            else: # Just append to existing row\n",
    "                rl += l\n",
    "                cc += 1\n",
    "                \n",
    "    # For very long labels just accept we can't do anything\n",
    "    max_cols = max(max_cols,1)\n",
    "\n",
    "    # distribute them roughly equally to avoid last row being awkwardly shorter\n",
    "    n_rows = int(math.ceil(len(cats)/max_cols))\n",
    "    return int(math.ceil(len(cats)/n_rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert estimate_legend_columns_horiz([\"Keskerakond\", \"EKRE\", \"Reformierakond\", \"Isamaa\", \"SDE\", \"Rohelised\", \"Eesti 200\", \"Parempoolsed\", \"Other\", \"None of the parties\", \"No opinion\"],800) == 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data options:\n",
    " - data_format: either 'longform' (default) or 'raw' for raw data\n",
    " - n_facets: tuple of how many internal facets the plot needs: (minimum, recommended)\n",
    " - draws: if it requires draws to be present (such as boxplots)\n",
    " - no_question_facet: for this plot question does not make sense as an internal facet (f.e. for density plots)\n",
    " - requires: list of dicts describing what we expect from each facet\n",
    "    - 'likert': True - requires category to be symmetric with the neutral/na value in middle for odd number of levels\n",
    "    - 'ordered': True - requires category to be ordered\n",
    "    - \\<any kw\\>: 'pass' - pass that value from column meta on to the function. useful for geoplot or electoral systems\n",
    " - args: dict of kw:type specifying what additional parameters the plot accepts via plot_args\n",
    " - priority: number that determines how likely this plot is to be picked as a default\n",
    " - group_size: requrests pp to add a column to data with size of each group. Needed for some plots that also represent group size\n",
    " - agg_fn: locks the aggregation function for continuous inputs (usually to sum, f.e. election modelling)\n",
    " - nonnegative: specifies that the value_col is expected to be non_negative for the plot to work properly\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Altair out-of-the-box boxplot. Slow if aggregating a lot of data (raw) and with ugly tooltips\n",
    "# Keeping it here for future reference\n",
    "@stk_plot('boxplots', data_format='longform', draws=True, n_facets=(1,2), priority=50)\n",
    "def boxplot_altair(data, value_col='value', facets=[], val_format='%', width=800, tooltip=[]):\n",
    "    f0, f1 = facets[0], facets[1] if len(facets)>1 else None\n",
    "\n",
    "    if val_format[-1] == '%': # Boxplots being a compound plot, this workaround is needed for axis & tooltips to be proper\n",
    "        data[value_col]*=100\n",
    "        val_format = val_format[:-1]+'f'\n",
    "    \n",
    "    shared = {\n",
    "        'y': alt.Y(f'{f0[\"col\"]}:N', title=None, sort=f0['order']),\n",
    "\n",
    "        **({\n",
    "            'color': alt.Color(f'{f0[\"col\"]}:N', scale=f0['colors'], legend=None)    \n",
    "            } if not f1 else {\n",
    "                'yOffset':alt.YOffset(f'{f1[\"col\"]}:N', title=None, sort=f1['order']), \n",
    "                'color': alt.Color(f'{f1[\"col\"]}:N', scale=f1['colors'], \n",
    "                                   legend=alt.Legend(orient='top',columns=estimate_legend_columns_horiz(f1['order'],width)))\n",
    "            })\n",
    "    }\n",
    "    \n",
    "    base = alt.Chart(round(data, 2))\n",
    "    \n",
    "    # This plot is here because boxplot does not draw if variance is very low, so this is the backup\n",
    "    tick_plot = base.mark_tick(thickness=3).encode(\n",
    "        x=alt.X(f'mean({value_col}):Q'),\n",
    "        tooltip=[alt.Tooltip(f'mean({value_col}):Q')] + tooltip[1:],\n",
    "        **shared\n",
    "    )\n",
    "    \n",
    "    box_plot = base.mark_boxplot(\n",
    "        clip=True,\n",
    "        #extent='min-max',\n",
    "        outliers=False\n",
    "    ).encode(\n",
    "        x=alt.X(\n",
    "            f'{value_col}:Q',\n",
    "            title=value_col,\n",
    "            axis=alt.Axis(format=val_format)\n",
    "            ),\n",
    "        tooltip=tooltip[1:],\n",
    "        **shared,\n",
    "    )\n",
    "    return tick_plot + box_plot\n",
    "\n",
    "# Also create a raw version for the same plot \n",
    "stk_plot('boxplots-raw', data_format=\"raw\", n_facets=(1,2), priority=0)(boxplot_altair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "# Regular boxplot with quantiles and Tukey whiskers\n",
    "def boxplot_vals(s,extent=1.5, delta=1e-4):\n",
    "    q1, q3 = s.quantile(0.25), s.quantile(0.75)\n",
    "    if q3-q1>2*delta: delta = 0.0 # only inflate when we need to\n",
    "    return pd.DataFrame({\n",
    "        'min': s.min(),\n",
    "        'q1': q1,\n",
    "        'q1p': q1-delta,\n",
    "        'mean': s.mean(),\n",
    "        'q2 (median)': s.median(),\n",
    "        'q3': q3,\n",
    "        'q3p': q3+delta,\n",
    "        'max': s.max(),\n",
    "        # Tukey values\n",
    "        'tmin': s[s>q1-extent*(q3-q1)].min(),\n",
    "        'tmax': s[s<q3+extent*(q3-q1)].max()\n",
    "    },index=['row'])\n",
    "\n",
    "\n",
    "@stk_plot('boxplots', data_format='longform', draws=True, n_facets=(1,2), priority=50, group_sizes=True)\n",
    "def boxplot_manual(data, value_col='value', facets=[], val_format='%', width=800, tooltip=[], outer_factors=[]):\n",
    "    f0, f1 = facets[0], facets[1] if len(facets)>1 else None\n",
    "\n",
    "    if val_format[-1] == '%': # Boxplots being a compound plot, this workaround is needed for axis & tooltips to be proper\n",
    "        data[value_col]*=100\n",
    "        val_format = val_format[:-1]+'f'\n",
    "    else: fit_beta_dist = False # Only use beta binomial for categoricals \n",
    "\n",
    "\n",
    "    minv,maxv = data[value_col].min(), data[value_col].max()\n",
    "    if val_format[-1] == '%': minv = 0.0\n",
    "    if minv==maxv: minv, maxv = minv-0.01, maxv+0.01\n",
    "\n",
    "    f_cols = outer_factors+[f['col'] for f in facets[:2] if f is not None]\n",
    "    df = data.groupby(f_cols,observed=True)[value_col].apply(boxplot_vals,delta=(maxv-minv)/400).reset_index()\n",
    "    \n",
    "    shared = {\n",
    "        'y': alt.Y(field=f0[\"col\"], type='nominal', title=None, sort=f0['order']),\n",
    "        **(\n",
    "            {'yOffset': alt.YOffset(field=f1[\"col\"], type='nominal', title=None, sort=f1['order'])} \n",
    "            if f1 else {}\n",
    "        ),\n",
    "        'tooltip': [\n",
    "            alt.Tooltip(field=vn, type='quantitative', format=val_format, \n",
    "                       title=f'{vn[0].upper()+vn[1:]} of {value_col}') \n",
    "            for vn in ['min','q1','mean','q2 (median)','q3','max']\n",
    "        ] + tooltip[1:]\n",
    "    }\n",
    "    \n",
    "    root = alt.Chart(df).encode(**shared)\n",
    "    size = 12\n",
    "\n",
    "    # Compose each layer individually\n",
    "    lower_plot = root.mark_rule().encode(\n",
    "        x=alt.X('tmin:Q', axis=alt.Axis(title=value_col, format=val_format), scale=alt.Scale(domain=[minv,maxv])),\n",
    "        x2=alt.X2('q1:Q'),\n",
    "    )\n",
    "\n",
    "    middle_plot = root.mark_bar(size=size).encode(\n",
    "        x=alt.X('q1p:Q'),\n",
    "        x2=alt.X2('q3p:Q'),\n",
    "        **({\n",
    "            'color': alt.Color(field=f0[\"col\"], type='nominal', scale=f0['colors'], legend=None)    \n",
    "        } if not f1 else {\n",
    "            'color': alt.Color(field=f1[\"col\"], type='nominal', scale=f1['colors'],\n",
    "                            legend=alt.Legend(orient='top',\n",
    "                                            columns=estimate_legend_columns_horiz(f1['order'],width)))\n",
    "        })\n",
    "    )\n",
    "\n",
    "    upper_plot = root.mark_rule().encode(\n",
    "        x=alt.X('q3:Q'),\n",
    "        x2=alt.X2('tmax:Q')\n",
    "    )\n",
    "\n",
    "    middle_tick = root.mark_tick(\n",
    "        color='white',\n",
    "        size=size\n",
    "    ).encode(\n",
    "        x='mean:Q',\n",
    "    )\n",
    "\n",
    "    return (lower_plot + middle_plot + upper_plot + middle_tick)\n",
    "# Also create a raw version for the same plot \n",
    "stk_plot('boxplots-raw', data_format=\"raw\", n_facets=(1,2), priority=0)(boxplot_manual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e2e_plot({\n",
    "    'res_col' : 'party_preference',\n",
    "    'factor_cols': ['age_group'],\n",
    "    'filter': {},\n",
    "    'plot': 'boxplots',\n",
    "    'internal_facet': True,\n",
    "},data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e2e_plot({\n",
    "    'res_col' : 'EKRE',\n",
    "    'factor_cols': ['age_group'],\n",
    "    'filter': {},\n",
    "    'plot': 'boxplots-raw',\n",
    "    'internal_facet': True\n",
    "},data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@stk_plot('columns', data_format='longform', draws=False, n_facets=(1,2))\n",
    "def columns(data, value_col='value', facets=[], val_format='%', width=800, tooltip=[]):\n",
    "    f0, f1 = facets[0], facets[1] if len(facets)>1 else None\n",
    "    plot = alt.Chart(data).mark_bar().encode(\n",
    "        x=alt.X(\n",
    "            field=value_col,\n",
    "            type='quantitative',\n",
    "            title=value_col,\n",
    "            axis=alt.Axis(format=val_format),\n",
    "        ),\n",
    "        y=alt.Y(field=f0[\"col\"], type='nominal', title=None, sort=f0[\"order\"]),\n",
    "        tooltip = tooltip,\n",
    "        **({\n",
    "            'color': alt.Color(field=f0[\"col\"], type='nominal', scale=f0[\"colors\"], legend=None)    \n",
    "        } if not f1 else {\n",
    "            'yOffset': alt.YOffset(field=f1[\"col\"], type='nominal', title=None, sort=f1[\"order\"]),\n",
    "            'color': alt.Color(field=f1[\"col\"], type='nominal', scale=f1[\"colors\"],\n",
    "                            legend=alt.Legend(orient='top',\n",
    "                                            columns=estimate_legend_columns_horiz(f1[\"order\"],width)))\n",
    "        }),\n",
    "    )\n",
    "    return plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e2e_plot({\n",
    "    'res_col' : 'e-valimised',\n",
    "    'factor_cols': ['nationality'],\n",
    "    'filter': {},\n",
    "    'plot': 'columns',\n",
    "    'internal_facet': True\n",
    "},data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e2e_plot({\n",
    "    'res_col' : 'thermometer',\n",
    "    'factor_cols': ['nationality'],\n",
    "    'filter': {},\n",
    "    'plot': 'columns',\n",
    "    'internal_facet': True\n",
    "},data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@stk_plot('stacked_columns', data_format='longform', draws=False, nonnegative=True, n_facets=(2,2), agg_fn='sum', args={'normalized':'bool'})\n",
    "def stacked_columns(data, value_col='value', facets=[], filtered_size=1, val_format='%', width=800, normalized=False, tooltip=[]):\n",
    "    f0, f1 = facets[0], facets[1]\n",
    "    \n",
    "    data[value_col] = data[value_col]/filtered_size\n",
    "    \n",
    "    ldict = dict(zip(f1[\"order\"], range(len(f1[\"order\"]))))\n",
    "    data['f_order'] = data[f1[\"col\"]].astype('object').replace(ldict).astype('int')\n",
    "    \n",
    "    plot = alt.Chart(round(data, 3), width = 'container' \\\n",
    "    ).mark_bar().encode(\n",
    "        x=alt.X(\n",
    "            field=value_col,\n",
    "            type='quantitative',\n",
    "            title=value_col,\n",
    "            axis=alt.Axis(format=val_format),\n",
    "            **({'stack':'normalize'} if normalized else {})\n",
    "            #scale=alt.Scale(domain=[0,30]) #see lõikab mõnedes jaotustes parema ääre ära\n",
    "        ),\n",
    "        y=alt.Y(field=f0[\"col\"], type='nominal', title=None, sort=f0[\"order\"]),\n",
    "        tooltip = tooltip,\n",
    "        **({\n",
    "            'color': alt.Color(field=f0[\"col\"], type='nominal', scale=f0[\"colors\"], legend=None)    \n",
    "        } if len(facets)<=1 else {\n",
    "            'order': alt.Order('f_order:O'),\n",
    "            'color': alt.Color(field=f1[\"col\"], type='nominal', scale=f1[\"colors\"],\n",
    "                            legend=alt.Legend(orient='top',\n",
    "                                            columns=estimate_legend_columns_horiz(f1[\"order\"],width)))\n",
    "        }),\n",
    "    )\n",
    "    return plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e2e_plot({\n",
    "  \"res_col\": \"party_preference\",\n",
    "  \"factor_cols\": [\"EKRE\"],\n",
    "  \"internal_facet\": True,\n",
    "  \"plot\": \"stacked_columns\",\n",
    "  \"plot_args\": {\n",
    "    \"normalized\": False\n",
    "  },\n",
    "  \"filter\": {}\n",
    "},data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@stk_plot('diff_columns', data_format='longform', draws=False, n_facets=(2,2), args={'sort_descending':'bool'})\n",
    "def diff_columns(data, value_col='value', facets=[], val_format='%', sort_descending=False, tooltip=[]):\n",
    "    f0, f1 = facets[0], facets[1]\n",
    "    \n",
    "    ind_cols = list(set(data.columns)-{value_col,f1[\"col\"]})\n",
    "    factors = data[f1[\"col\"]].unique() # use unique instead of categories to allow filters to select the two that remain\n",
    "    \n",
    "    idf = data.set_index(ind_cols)\n",
    "    diff = (idf[idf[f1[\"col\"]]==factors[1]][value_col]-idf[idf[f1[\"col\"]]==factors[0]][value_col]).reset_index()\n",
    "    \n",
    "    if sort_descending: f0[\"order\"] = list(diff.sort_values(value_col,ascending=False)[f0[\"col\"]])\n",
    "    \n",
    "    plot = alt.Chart(round(diff, 3), width = 'container' \\\n",
    "    ).mark_bar().encode(\n",
    "        y=alt.Y(field=f0[\"col\"], type='nominal', title=None, sort=f0[\"order\"]),\n",
    "        x=alt.X(\n",
    "            field=value_col,\n",
    "            type='quantitative',\n",
    "            title=f\"{factors[1]} - {factors[0]}\",\n",
    "            axis=alt.Axis(format=val_format, title=f\"{factors[0]} <> {factors[1]}\"),\n",
    "            #scale=alt.Scale(domain=[0,30]) #see lõikab mõnedes jaotustes parema ääre ära\n",
    "        ), \n",
    "        tooltip=[\n",
    "            alt.Tooltip(field=f0[\"col\"], type='nominal'),\n",
    "            alt.Tooltip(field=value_col, type='quantitative', format=val_format, title=f'{value_col} difference')\n",
    "        ],\n",
    "        color=alt.Color(field=f0[\"col\"], type='nominal', scale=f0[\"colors\"], legend=None)    \n",
    "    )\n",
    "    return plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e2e_plot({\n",
    "    'res_col' : 'thermometer',\n",
    "    'factor_cols': ['age_group'],\n",
    "    'filter': { 'age_group': [None,'25-34','35-44']},\n",
    "    'plot': 'diff_columns',\n",
    "    'internal_facet': True,\n",
    "    'plot_args': { 'sort_descending': True }\n",
    "},data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "# The idea was to also visualize the size of each cluster. Currently not very useful, may need to be rethought\n",
    "@stk_plot('massplot', data_format='longform', draws=False, group_sizes=True, n_facets=(1,2), hidden=True)\n",
    "def massplot(data, value_col='value', facets=[], filtered_size=1, val_format='%', width=800, tooltip=[]):\n",
    "    f0, f1 = facets[0], facets[1] if len(facets)>1 else None\n",
    "\n",
    "    data['group_size']=(data['group_size']/filtered_size)#.round(2)\n",
    "\n",
    "    plot = alt.Chart(round(data, 3), width = 'container' \\\n",
    "    ).mark_circle().encode(\n",
    "        y=alt.Y(field=f0[\"col\"], type='nominal', title=None, sort=f0[\"order\"]),\n",
    "        x=alt.X(\n",
    "            field=value_col,\n",
    "            type='quantitative',\n",
    "            title=value_col,\n",
    "            axis=alt.Axis(format=val_format),\n",
    "            #scale=alt.Scale(domain=[0,30]) #see lõikab mõnedes jaotustes parema ääre ära\n",
    "            ),\n",
    "        size=alt.Size('group_size:Q', legend=None, scale=alt.Scale(range=[100, 500])),\n",
    "        opacity=alt.value(1.0),\n",
    "        stroke=alt.value('#777'),\n",
    "        tooltip = tooltip + [ alt.Tooltip('group_size:N',format='.1%',title='Group size') ],\n",
    "        **({\n",
    "            'color': alt.Color(field=f0[\"col\"], type='nominal', scale=f0[\"colors\"], legend=None)    \n",
    "        } if not f1 else {\n",
    "            'yOffset': alt.YOffset(field=f1[\"col\"], type='nominal', title=None, sort=f1[\"order\"]), \n",
    "            'color': alt.Color(field=f1[\"col\"], type='nominal', scale=f1[\"colors\"],\n",
    "                            legend=alt.Legend(orient='top',\n",
    "                                            columns=estimate_legend_columns_horiz(f1[\"order\"],width)))\n",
    "        }),\n",
    "    )\n",
    "    return plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e2e_plot({\n",
    "    'res_col' : 'trust',\n",
    "    'factor_cols': ['party_preference'],\n",
    "    'filter': {},\n",
    "    'plot': 'massplot',\n",
    "    'internal_facet': True,\n",
    "    'convert_res': 'continuous'\n",
    "},data_file)#,dry_run=True)['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "# Make the likert bar pieces\n",
    "def make_start_end(x,value_col,cat_col,cat_order,neutral,n_negative):\n",
    "    #print(\"######################\")\n",
    "    #print(value_col,cat_order)\n",
    "    #print(x)\n",
    "    if len(x) != len(cat_order):\n",
    "        shared = x.to_dict(orient='records')[0]\n",
    "        # Fill in missing rows with value zero so they would just be skipped\n",
    "        mdf = pd.DataFrame({cat_col:pd.Categorical(cat_order,cat_order,ordered=True)})\n",
    "        x = pd.merge(mdf,x,on=cat_col,how='left').fillna({**shared,value_col:0})\n",
    "    x = x.sort_values(by=cat_col)\n",
    "    #print(x)\n",
    "\n",
    "    if len(neutral)==0: # No neutrals\n",
    "        x_other = x.copy()\n",
    "        x_mids = []\n",
    "    else: # Handle neutrals    \n",
    "        mids = neutral\n",
    "        nonmid = [ i for i in range(len(x)) if i not in mids ]\n",
    "    \n",
    "        scale_start = -1.0\n",
    "        x_mid = x.iloc[mids,:].copy()\n",
    "        x_other = x.iloc[nonmid,:].copy()        \n",
    "\n",
    "        # Compute the positions of the neutrals\n",
    "        x_mid.loc[:,'end'] = scale_start + x_mid[value_col].cumsum()\n",
    "        x_mid.loc[:,'start'] = x_mid.loc[:,'end'] - x_mid[value_col]\n",
    "        x_mids = [x_mid]\n",
    "    \n",
    "    o_mid = n_negative\n",
    "    x_other.loc[:,'end'] = x_other[value_col].cumsum() - x_other[:o_mid][value_col].sum()\n",
    "    x_other.loc[:,'start'] = (x_other[value_col][::-1].cumsum()[::-1] - x_other[o_mid:][value_col].sum())*-1\n",
    "    res = pd.concat([x_other] + x_mids).dropna(subset=[value_col]) # drop any na rows added in the filling in step\n",
    "    #print(\"RES\",res)\n",
    "    return res\n",
    "\n",
    "@stk_plot('likert_bars', data_format='longform', draws=False, requires=[{'likert':True}], n_facets=(1,3), sort_numeric_first_facet=True, priority=50)\n",
    "def likert_bars(data, value_col='value', facets=[],  tooltip=[], outer_factors=[], width=800):\n",
    "    # First facet is likert, second is labeled question, third is offset. Second is better for question which usually goes last, hence reorder\n",
    "    if len(facets)==1: # Create a dummy second facet\n",
    "        facets.append({ 'col': 'question', 'order': [facets[0]['col']], 'colors': alt.Undefined })\n",
    "        data['question'] = facets[0]['col']\n",
    "    if len(facets)>=3: f0, f1, f2 = facets[0], facets[2], facets[1]\n",
    "    elif len(facets)==2: f0, f1, f2 = facets[0], facets[1], None\n",
    "\n",
    "    # Split the categories into negative, neutral, positive same way that colors were allocated\n",
    "    neg,neutral,pos = split_to_neg_neutral_pos(f0['order'],f0.get('neutrals',[]))\n",
    "    ninds = [ f0['order'].index(c) for c in neutral ]\n",
    "\n",
    "    gb_cols = outer_factors+[f[\"col\"] for f in facets[1:]] # There can be other extra cols (like labels) that should be ignored\n",
    "    options_cols = list(data[f0[\"col\"]].dtype.categories) # Get likert scale names\n",
    "    bar_data = data.groupby(gb_cols, group_keys=False, observed=False)[data.columns]\\\n",
    "                        .apply(make_start_end, value_col=value_col,cat_col=f0[\"col\"],cat_order=f0[\"order\"],\n",
    "                            include_groups=False,neutral=ninds,n_negative=len(neg))\n",
    "    \n",
    "    plot = alt.Chart(bar_data).mark_bar() \\\n",
    "        .encode(\n",
    "            x=alt.X('start:Q', axis=alt.Axis(title=None, format = '%')),\n",
    "            x2=alt.X2('end:Q'),\n",
    "            y=alt.Y(field=f1[\"col\"], type='nominal', \n",
    "                    axis=alt.Axis(title=None, offset=5, ticks=False, minExtent=60, domain=False), \n",
    "                    sort=f1[\"order\"]),\n",
    "            tooltip=tooltip,\n",
    "            color=alt.Color(\n",
    "                field=f0[\"col\"],\n",
    "                type='nominal',\n",
    "                legend=alt.Legend(\n",
    "                    title=None,#f0[\"col\"],\n",
    "                    orient='bottom',\n",
    "                    columns=estimate_legend_columns_horiz(f0['order'],width,extra_text=f1['order'])\n",
    "                ),\n",
    "                scale=f0[\"colors\"],\n",
    "            ),\n",
    "            **({ \n",
    "                'yOffset': alt.YOffset(field=f2[\"col\"], type='nominal', title=None, sort=f2[\"order\"])\n",
    "            } if f2 else {})\n",
    "        )\n",
    "    return plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e2e_plot({\n",
    "    'res_col' : 'trust',\n",
    "    'factor_cols': ['party_preference'],  'filter': {},\n",
    "    'plot': 'likert_bars',\n",
    "    'internal_facet': True\n",
    "},data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e2e_plot({\n",
    "    'res_col' : 'trust',\n",
    "    'factor_cols': ['party_preference'],  'filter': {},\n",
    "    'plot': 'likert_bars',\n",
    "    'internal_facet': True\n",
    "},data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e2e_plot({\n",
    "    'res_col' : 'valitsus',\n",
    "    'factor_cols': [],  'filter': {},\n",
    "    'plot': 'likert_bars',\n",
    "    'internal_facet': True\n",
    "},data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "# Calculate the bandwidth for KDE\n",
    "def kde_bw(ar):\n",
    "    # Lower-bound silverman by min_diff to smooth out categorical density plots\n",
    "    return max(silvermans_rule(ar) or 0.0, 0.75*min_diff(ar[:,0]))\n",
    "\n",
    "# Calculate KDE ourselves using a fast libary. This gets around having to do sampling which is unstable\n",
    "def kde_1d(vc, value_col, ls, scale=False, bw=None):\n",
    "    ar = vc.to_numpy()\n",
    "    if bw is None: bw = kde_bw(ar) # This can be problematic in small segments, so best calculated globally\n",
    "    y =  FFTKDE(kernel='gaussian',bw=bw).fit(ar).evaluate(ls)\n",
    "    if scale: y*=len(vc)\n",
    "    return pd.DataFrame({'density': y, value_col: ls})\n",
    "\n",
    "@stk_plot('density', factor_columns=3, draws=True, aspect_ratio=(1.0/1.0), n_facets=(0,1), args={'stacked':'bool', 'bw':'float'}, no_question_facet=True)\n",
    "def density(data, value_col='value', facets=[], tooltip=[], outer_factors=[], stacked=False, bw=None, width=800):\n",
    "    f0 = facets[0] if len(facets)>0 else None\n",
    "    gb_cols = [ c for c in outer_factors+[f['col'] for f in facets] if c is not None ] # There can be other extra cols (like labels) that should be ignored\n",
    "\n",
    "    # Filter out extreme outliers (one thousandth on each side). \n",
    "    # Because at 100k+, these get very extreme even for normal distributions\n",
    "    lims = list(data[value_col].quantile([.005,0.995]))\n",
    "    data = data[(data[value_col]>=lims[0]) & (data[value_col]<=lims[1])]\n",
    "    \n",
    "    ls = np.linspace(data[value_col].min()-1e-10,data[value_col].max()+1e-10,100)\n",
    "    if bw is None: bw = kde_bw(data[[value_col]].sample(10000,replace=True).to_numpy()) # Can get slow for large data otherwise\n",
    "    ndata = gb_in_apply(data,gb_cols,cols=[value_col],fn=kde_1d,value_col=value_col,ls=ls,scale=stacked,bw=bw).reset_index()\n",
    "\n",
    "    if f0: selection = alt.selection_point(fields=[f0[\"col\"]], bind='legend')\n",
    "\n",
    "    if stacked: \n",
    "        if f0:\n",
    "            ldict = dict(zip(f0[\"order\"], reversed(range(len(f0[\"order\"])))))\n",
    "            ndata.loc[:,'order'] = ndata[f0[\"col\"]].astype('object').replace(ldict).astype('int')\n",
    "        \n",
    "        ndata['density'] /= len(data)\n",
    "        plot=alt.Chart(ndata).mark_area(interpolate='natural').encode(\n",
    "            x=alt.X(field=value_col, type='quantitative'),\n",
    "            y=alt.Y('density:Q', axis=alt.Axis(title=None, format='%'), stack='zero'),\n",
    "            tooltip=tooltip[1:],\n",
    "            **({'fill': alt.Fill(field=f0[\"col\"], type='nominal', scale=f0[\"colors\"], \n",
    "                                legend=alt.Legend(orient='top',\n",
    "                                                columns=estimate_legend_columns_horiz(f0[\"order\"],width))), \n",
    "                'order': alt.Order('order:O'), \n",
    "                'opacity': alt.condition(selection, alt.value(1), alt.value(0.15))\n",
    "                } if f0 else {})\n",
    "        )\n",
    "    else:\n",
    "        plot = alt.Chart(ndata).mark_line().encode(\n",
    "            x=alt.X(field=value_col, type='quantitative'),\n",
    "            y=alt.Y('density:Q', axis=alt.Axis(title=None, format='%')),\n",
    "            tooltip=tooltip[1:],\n",
    "            **({'color': alt.Color(field=f0[\"col\"], type='nominal', scale=f0[\"colors\"], \n",
    "                                legend=alt.Legend(orient='top',\n",
    "                                        columns=estimate_legend_columns_horiz(f0[\"order\"],width))),\n",
    "                'order': alt.Order('order:O'), \n",
    "                'opacity': alt.condition(selection, alt.value(1), alt.value(0.15))\n",
    "                } if f0 else {})\n",
    "        )\n",
    "\n",
    "    if f0: plot = plot.add_params(selection)\n",
    "\n",
    "    return plot\n",
    "\n",
    "# Also create a raw version for the same plot \n",
    "stk_plot('density-raw', data_format=\"raw\", factor_columns=3, aspect_ratio=(1.0/1.0), n_facets=(0,1), args={'stacked':'bool', 'bw':'float'}, no_question_facet=True, priority=0)(density)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e2e_plot({\n",
    "    'res_col' : 'thermometer',\n",
    "    'factor_cols': ['party_preference'],  'filter': {},\n",
    "    'plot': 'density-raw',\n",
    "    'plot_args': {'stacked': True},\n",
    "    'internal_facet': True\n",
    "},data_file,width=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@stk_plot('violin', n_facets=(1,2), draws=True, as_is=True, args={'bw':'float'})\n",
    "def violin(data, value_col='value', facets=[], tooltip=[], outer_factors=[], bw=None, width=800):\n",
    "    f0, f1 = facets[0], facets[1] if len(facets)>1 else None\n",
    "    gb_cols = outer_factors + [ f['col'] for f in facets ] # There can be other extra cols (like labels) that should be ignored\n",
    "    \n",
    "    ls = np.linspace(data[value_col].min()-1e-10,data[value_col].max()+1e-10,200)\n",
    "    if bw is None: bw = kde_bw(data[[value_col]].sample(10000,replace=True).to_numpy())\n",
    "    ndata = gb_in_apply(data,gb_cols,cols=[value_col],fn=kde_1d,value_col=value_col,ls=ls,scale=True,bw=bw).reset_index()\n",
    "    \n",
    "    if f1:\n",
    "        ldict = dict(zip(f1[\"order\"], reversed(range(len(f1[\"order\"])))))\n",
    "        ndata.loc[:,'order'] = ndata[f1[\"col\"]].astype('object').replace(ldict).astype('int')\n",
    "\n",
    "    ndata['density'] /= len(data)\n",
    "    plot=alt.Chart(ndata).mark_area(interpolate='natural').encode(\n",
    "            x=alt.X(field=value_col, type='quantitative'),\n",
    "            y=alt.Y('density:Q',axis=alt.Axis(title=None, labels=False, values=[0], grid=False),stack='center'),\n",
    "            row=alt.Row(field=f0[\"col\"], type='nominal', \n",
    "                header=alt.Header(orient='top',title=None), spacing=5, sort=f0[\"order\"]),\n",
    "            tooltip = tooltip[1:],\n",
    "            #color=alt.Color(f'{question_col}:N'),\n",
    "            **({'color': alt.Color(field=f1[\"col\"], type='nominal', scale=f1[\"colors\"], \n",
    "                    legend=alt.Legend(orient='top',\n",
    "                            columns=estimate_legend_columns_horiz(f1[\"order\"],width))), \n",
    "                    'order': alt.Order('order:O')} if f1 else \n",
    "                {'color': alt.Color(field=f0[\"col\"], type='nominal', scale=f0[\"colors\"], legend=None)})\n",
    "        ).properties(width=width,height=70)\n",
    "\n",
    "    return plot\n",
    "\n",
    "# Also create a raw version for the same plot \n",
    "stk_plot('violin-raw', data_format='raw', n_facets=(1,2), as_is=True, args={'bw':'float'})(violin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e2e_plot({\n",
    "    'res_col' : 'thermometer',\n",
    "    'factor_cols': ['party_preference'],  'filter': {},\n",
    "    'plot': 'violin-raw',\n",
    "    'internal_facet': True\n",
    "},data_file, width=650)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "# Cluster-based reordering\n",
    "def cluster_based_reorder(X):\n",
    "    pd = sp.spatial.distance.pdist(X)#,metric='cosine')\n",
    "    return hierarchy.leaves_list(hierarchy.optimal_leaf_ordering(hierarchy.ward(pd), pd))\n",
    "\n",
    "@stk_plot('matrix', data_format='longform', aspect_ratio=(1/0.8), n_facets=(2,2), args={'reorder':'bool', 'log_colors':'bool'})\n",
    "def matrix(data, value_col='value', facets=[], val_format='%', reorder=False, log_colors=False, tooltip=[]):\n",
    "    f0, f1 = facets[0], facets[1]\n",
    "    \n",
    "    fcols = [c for c in data.columns if c not in [value_col,f0[\"col\"]]]\n",
    "    if len(fcols)==1 and reorder: # Reordering only works if no external facets\n",
    "        X = data.pivot(columns=f1[\"col\"],index=f0[\"col\"]).to_numpy()\n",
    "        f0[\"order\"] = np.array(f0[\"order\"])[cluster_based_reorder(X)]\n",
    "        f1[\"order\"] = np.array(f1[\"order\"])[cluster_based_reorder(X.T)]\n",
    "    \n",
    "    if log_colors:\n",
    "        data['val_log'] = np.log(data[value_col])\n",
    "        data['val_log'] -= data['val_log'].min() # Keep it all positive \n",
    "        scale_v = 'val_log'\n",
    "    else: scale_v = value_col\n",
    "\n",
    "    # Find max absolute value to keep color scale symmetric\n",
    "    mi, ma = data[scale_v].min(),data[scale_v].max() \n",
    "    dmax = float(max(-mi,ma))\n",
    "\n",
    "    if mi<0: scale, smid, swidth = { 'scheme':'redyellowgreen', 'domainMid':0, 'domainMin':-dmax, 'domainMax':dmax }, 0, 2*dmax\n",
    "    else: scale, smid, swidth = { 'scheme': 'yellowgreen', 'domainMin': 0, 'domainMax':dmax }, 0, 2*dmax, #dmax/2, dmax \n",
    "\n",
    "    # Draw colored boxes\n",
    "    plot = alt.Chart(data).mark_rect().encode(\n",
    "        x=alt.X(field=f1[\"col\"], type='nominal', title=None, sort=f1[\"order\"]),\n",
    "        y=alt.Y(field=f0[\"col\"], type='nominal', title=None, sort=f0[\"order\"]),\n",
    "        color=alt.Color(field=scale_v, type='quantitative', \n",
    "                        scale=alt.Scale(**scale), \n",
    "                        legend=(alt.Legend(title=None) if not log_colors else None)),\n",
    "        tooltip=tooltip,\n",
    "    )\n",
    "    \n",
    "    # Add in numerical values\n",
    "    if len(f1[\"order\"])<20: # only if we have less than 20 columns\n",
    "        text = plot.mark_text().encode(\n",
    "            text=alt.Text(field=value_col, type='quantitative', format=val_format),\n",
    "            color=alt.condition(\n",
    "                (alt.datum[scale_v]-smid)**2 > (0.25*swidth)**2,\n",
    "                alt.value('white'),\n",
    "                alt.value('black')\n",
    "            ),\n",
    "            tooltip=tooltip\n",
    "        )\n",
    "        plot += text\n",
    "        \n",
    "    return plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e2e_plot({\n",
    "    'res_col' : 'party_preference',\n",
    "    'factor_cols': [ 'age_group'],  'filter': {},\n",
    "    'plot': 'matrix',\n",
    "    'internal_facet': True\n",
    "},data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e2e_plot({\n",
    "    'res_col' : 'thermometer',\n",
    "    'factor_cols': [ 'party_preference'],  'filter': {},\n",
    "    'plot': 'matrix',\n",
    "    'internal_facet': True\n",
    "},data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e2e_plot({\n",
    "    'res_col' : 'wedge',\n",
    "    'factor_cols': [ 'party_preference'],  'filter': {},\n",
    "    'plot': 'matrix',\n",
    "    'plot_args': { 'reorder':True },\n",
    "    'internal_facet': True,\n",
    "    'convert_res': 'continuous',\n",
    "    'cont_transform': 'center'\n",
    "},data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@stk_plot('corr_matrix', data_format='raw', aspect_ratio=(1/0.8), n_facets=(1,1))\n",
    "def corr_matrix(data, value_col='value', facets=[], val_format='%', reorder=False, tooltip=[]):\n",
    "    if 'id' not in data.columns: raise Exception(\"Corr_matrix only works for groups of continuous variables\")\n",
    "\n",
    "    # id is required to match the rows for correllations\n",
    "    cm = data.pivot_table(index='id',columns=facets[0]['col'],values=value_col,observed=False).corr().reset_index(names='index')\n",
    "    cm_long = cm.melt(id_vars=['index'],value_vars=cm.columns, var_name=facets[0]['col'], value_name=value_col)\n",
    "\n",
    "    order = facets[0]['order'] \n",
    "    lower_tri = (cm_long['index'].map(lambda x: order.index(x)).astype(int)>cm_long[facets[0]['col']].map(lambda x: order.index(x)).astype(int))\n",
    "    cm_long = cm_long[lower_tri]\n",
    "    \n",
    "    return matrix(cm_long, value_col=value_col, facets=[{'col':'index','order':facets[0]['order']},{'col':facets[0]['col'],'order':facets[0]['order']}], val_format=val_format,\n",
    "                  tooltip=[alt.Tooltip(field=value_col, type='quantitative'),alt.Tooltip('index:N'),alt.Tooltip(field=facets[0]['col'], type='nominal')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e2e_plot({\n",
    "    'res_col' : 'thermometer',\n",
    "    'factor_cols': [],  'filter': {},\n",
    "    'plot': 'corr_matrix',\n",
    "    'internal_facet': True\n",
    "},data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@stk_plot('lines',data_format='longform', draws=False, requires=[{},{'ordered':True}], n_facets=(2,2), args={'smooth':'bool'}, priority=10)\n",
    "def lines(data, value_col='value', facets=[], smooth=False, width=800, tooltip=[], val_format='.2f',):\n",
    "    f0, f1 = facets[0], facets[1]\n",
    "    if smooth:\n",
    "        smoothing = 'basis'\n",
    "        points = 'transparent'\n",
    "    else:\n",
    "        smoothing = 'natural'\n",
    "        points = True\n",
    "    plot = alt.Chart(data).mark_line(point=points, interpolate=smoothing).encode(\n",
    "        x=alt.X(field=f1[\"col\"], type='nominal', title=None, sort=f1[\"order\"],axis=alt.Axis(labelAngle=0)),\n",
    "        y=alt.Y(field=value_col, type='quantitative', axis=alt.Axis(format=val_format)),\n",
    "        tooltip=tooltip,\n",
    "        color=alt.Color(field=f0[\"col\"], type='nominal', scale=f0[\"colors\"], sort=f0[\"order\"],\n",
    "                        legend=alt.Legend(orient='top',\n",
    "                                    columns=estimate_legend_columns_horiz(f0[\"order\"],width)))\n",
    "    )\n",
    "    return plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e2e_plot({\n",
    "    'res_col' : 'thermometer',\n",
    "    'factor_cols': ['education'],  'filter': {},\n",
    "    'plot': 'lines',\n",
    "    'internal_facet': True,\n",
    "    'plot_args': { 'smooth':True }\n",
    "},data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def draws_to_hdis(data,vc,hdi_vals):\n",
    "    gbc = [ c for c in data.columns if c not in [vc,'draw'] ]\n",
    "    ldfs = []\n",
    "    for hdiv in hdi_vals:\n",
    "        ldf_v = data.groupby(gbc,observed=False)[vc].apply(lambda s: pd.Series(list(az.hdi(s.to_numpy(),hdi_prob=hdiv)),index=['lo','hi'])).reset_index()\n",
    "        ldf_v['hdi']=hdiv\n",
    "        ldfs.append(ldf_v)\n",
    "    ldf = pd.concat(ldfs).reset_index(drop=True)\n",
    "    df = ldf.pivot(index=gbc+['hdi'], columns=ldf.columns[-3],values=vc).reset_index()\n",
    "    return df\n",
    "\n",
    "@stk_plot('lines_hdi',data_format='longform', draws=True, requires=[{},{'ordered':True}], n_facets=(2,2), args={'hdi1':'float','hdi2':'float'})\n",
    "def lines_hdi(data, value_col='value', facets=[], width=800, tooltip=[], val_format='.2f', hdi1=0.94, hdi2=0.5):\n",
    "    f0, f1 = facets[0], facets[1]\n",
    "    \n",
    "    hdf = draws_to_hdis(data,value_col,[hdi1,hdi2])\n",
    "    # Draw them in reverse order so the things that are first (i.e. most important) are drawn last (i.e. on top of others)\n",
    "    # Also draw wider hdi before the narrower\n",
    "    hdf.sort_values([f0[\"col\"],'hdi'],ascending=[False,False],inplace=True)\n",
    "\n",
    "    selection = alt.selection_point(fields=[f0[\"col\"]], bind='legend')\n",
    "\n",
    "    plot = alt.Chart(hdf).mark_area(interpolate='basis').encode(\n",
    "        x=alt.X(field=f1[\"col\"], type='ordinal', title=None, sort=f1[\"order\"], axis=alt.Axis(labelAngle=0)),\n",
    "        y=alt.Y('lo:Q',\n",
    "            axis=alt.Axis(format=val_format),\n",
    "            title=value_col\n",
    "            ),\n",
    "        y2=alt.Y2('hi:Q'),\n",
    "        fill=alt.Fill(\n",
    "            field=f0[\"col\"],\n",
    "            type='nominal',\n",
    "            sort=f0[\"order\"],\n",
    "            scale=f0[\"colors\"],\n",
    "            legend=alt.Legend(symbolOpacity=1)\n",
    "            ),\n",
    "        opacity=alt.condition(selection, \n",
    "            alt.Opacity('hdi:N', legend=None, scale=to_alt_scale({0.5:0.75, 0.94:0.25})),\n",
    "            alt.value(0.1)\n",
    "        ),\n",
    "        tooltip=[\n",
    "            alt.Tooltip('hdi:N', title='HDI', format='.0%'),\n",
    "            alt.Tooltip('lo:Q', title='HDI lower', format=val_format),\n",
    "            alt.Tooltip('hi:Q', title='HDI upper', format=val_format),] + tooltip[1:]\n",
    "        ).add_params(selection)\n",
    "    return plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e2e_plot({\n",
    "    'res_col' : 'party_preference',\n",
    "    'factor_cols': ['age_group','nationality'],  'filter': {},\n",
    "    'plot': 'lines_hdi',\n",
    "    'internal_facet': True,\n",
    "},data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@stk_plot('area_smooth',data_format='longform', draws=False, nonnegative=True, requires=[{},{'ordered':True}], n_facets=(2,2))\n",
    "def area_smooth(data, value_col='value', facets=[], width=800, tooltip=[]):\n",
    "    f0, f1 = facets[0], facets[1]\n",
    "    ldict = dict(zip(f0[\"order\"], range(len(f0[\"order\"]))))\n",
    "    data.loc[:,'order'] = data[f0[\"col\"]].astype('object').replace(ldict).astype('int')\n",
    "    plot=alt.Chart(data\n",
    "        ).mark_area(interpolate='natural').encode(\n",
    "            x=alt.X(field=f1[\"col\"], type='ordinal', title=None, sort=f1[\"order\"], axis=alt.Axis(labelAngle=0)),\n",
    "            y=alt.Y(field=value_col, type='quantitative', title=None, stack='normalize',\n",
    "                 scale=alt.Scale(domain=[0, 1]), axis=alt.Axis(format='%')\n",
    "                 ),\n",
    "            order=alt.Order('order:O'),\n",
    "            color=alt.Color(field=f0[\"col\"], type='nominal',\n",
    "                legend=alt.Legend(orient='top',columns=estimate_legend_columns_horiz(f0[\"order\"],width)),\n",
    "                sort=f0[\"order\"], scale=f0[\"colors\"]\n",
    "                ),\n",
    "            tooltip=tooltip\n",
    "        )\n",
    "    return plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e2e_plot({\n",
    "    'res_col' : 'party_preference',\n",
    "    'factor_cols': ['education','gender'],  'filter': {},\n",
    "    'plot': 'area_smooth',\n",
    "    'internal_facet': True\n",
    "},data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def likert_aggregate(x, cat_col, cat_order, value_col):\n",
    "    \n",
    "    cc, vc = x[cat_col], x[value_col]\n",
    "    cats = cat_order\n",
    "    \n",
    "    mid, odd = len(cats)//2, len(cats)%2\n",
    "    \n",
    "    nonmid_sum = vc[cc !=  cats[mid]].sum() if odd else vc.sum()\n",
    "    \n",
    "    #print(len(x),x.columns,x.head())\n",
    "    pol = ( np.minimum(\n",
    "                vc[cc.isin(cats[:mid])].sum(),\n",
    "                vc[cc.isin(cats[mid+odd:])].sum()\n",
    "            ) / nonmid_sum )\n",
    "\n",
    "    rad = ( vc[cc.isin([cats[0],cats[-1]])].sum() /\n",
    "            nonmid_sum )\n",
    "\n",
    "    rel = 1.0-nonmid_sum/vc.sum()\n",
    "    \n",
    "    return pd.Series({ 'polarisation': pol, 'radicalisation':rad, 'relevance':rel})\n",
    "\n",
    "@stk_plot('likert_rad_pol',data_format='longform', requires=[{'likert':True}], args={'normalized':'bool'}, n_facets=(1,2))\n",
    "def likert_rad_pol(data, value_col='value', facets=[], normalized=True, width=800, outer_factors=[], tooltip=[]):\n",
    "    f0, f1 = facets[0], facets[1] if len(facets)>1 else None\n",
    "    #gb_cols = list(set(data.columns)-{ f0[\"col\"], value_col }) # Assume all other cols still in data will be used for factoring\n",
    "    gb_cols = outer_factors + [f['col'] for f in facets[1:]] # There can be other extra cols (like labels) that should be ignored\n",
    "    likert_indices = gb_in_apply(data,gb_cols,likert_aggregate,cat_col=f0[\"col\"],cat_order=f0[\"order\"],value_col=value_col).reset_index()\n",
    "    \n",
    "    if normalized and len(likert_indices)>1: likert_indices.loc[:,['polarisation','radicalisation']] = likert_indices[['polarisation','radicalisation']].apply(sps.zscore)\n",
    "    \n",
    "    if f1: selection = alt.selection_point(fields=[f1[\"col\"]], bind='legend')\n",
    "        \n",
    "    plot = alt.Chart(likert_indices).mark_point().encode(\n",
    "        x=alt.X('polarisation:Q'),\n",
    "        y=alt.Y('radicalisation:Q'),\n",
    "        size=alt.Size('relevance:Q', legend=None, scale=alt.Scale(range=[100, 500])),\n",
    "        #stroke=alt.value('#777'),\n",
    "        tooltip=[\n",
    "            alt.Tooltip('radicalisation:Q', format='.2'),\n",
    "            alt.Tooltip('polarisation:Q', format='.2'),\n",
    "            alt.Tooltip('relevance:Q', format='.2')\n",
    "        ] + tooltip[2:],\n",
    "        **({'color': alt.Color(field=f1[\"col\"], type='nominal', scale=f1[\"colors\"], \n",
    "                                legend=alt.Legend(orient='top',columns=estimate_legend_columns_horiz(f1[\"order\"],width))),\n",
    "            'opacity':alt.condition(selection, alt.value(1), alt.value(0.15)),\n",
    "            } if f1 else {})\n",
    "        )\n",
    "    if f1: plot = plot.add_params(selection)\n",
    "    \n",
    "    return plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e2e_plot({\n",
    "  \"res_col\": \"referendum\",\n",
    "  \"factor_cols\": [\n",
    "    \"electoral_district\"\n",
    "  ],\n",
    "  \"internal_facet\": True,\n",
    "  \"plot\": \"likert_rad_pol\",\n",
    "  \"filter\": {}\n",
    "},'../samples/master_bootstrap.parquet',width=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@stk_plot('barbell', data_format='longform', draws=False, n_facets=(2,2))\n",
    "def barbell(data, value_col='value', facets=[], filtered_size=1, val_format='%', width=800, tooltip=[]):\n",
    "    f0, f1 = facets[0], facets[1]\n",
    "    \n",
    "    chart_base = alt.Chart(data).encode(\n",
    "        x=alt.X(field=value_col, type='quantitative', title=None, axis=alt.Axis(format=val_format)),\n",
    "        y=alt.Y(field=f0[\"col\"], type='nominal', title=None, sort=f0[\"order\"]),\n",
    "        tooltip=tooltip\n",
    "    )\n",
    "\n",
    "    chart = chart_base.mark_line(color='lightgrey', size=1, opacity=1.0).encode(\n",
    "        detail=alt.Detail(field=f0[\"col\"], type='nominal')\n",
    "    )\n",
    "    selection = alt.selection_point(fields=[f1[\"col\"]], bind='legend')\n",
    "\n",
    "    chart += chart_base.mark_point(\n",
    "        size=50,\n",
    "        opacity=1,\n",
    "        filled=True\n",
    "    ).encode(\n",
    "        color=alt.Color(field=f1[\"col\"], type='nominal',\n",
    "            #legend=alt.Legend(orient='right', title=None),\n",
    "            legend=alt.Legend(orient='top',columns=estimate_legend_columns_horiz(f1[\"order\"],width)),\n",
    "            scale=f1[\"colors\"],\n",
    "            sort=f1[\"order\"]\n",
    "        ),\n",
    "        opacity=alt.condition(selection, alt.value(1), alt.value(0.15)),\n",
    "    ).add_params(\n",
    "        selection\n",
    "    )#.interactive()\n",
    "    \n",
    "    return chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e2e_plot({\n",
    "    'res_col' : 'trust',\n",
    "    'factor_cols': ['party_preference'],\n",
    "    'filter': {},\n",
    "    'plot': 'barbell',\n",
    "    'internal_facet': True,\n",
    "    'convert_res': 'continuous'\n",
    "},data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This does not work because of a Vega lite bug: https://github.com/altair-viz/altair/issues/2369 -> https://github.com/vega/vega-lite/issues/3729\n",
    "#@stk_plot('geoplot', data_format='longform', factor_meta=['topo_feature'])\n",
    "def geoplot_ideal(data, value_col='value', facets=[], val_format='%'):\n",
    "    f0, f1 = facets[0], facets[1]\n",
    "    \n",
    "    # TODO: replace with data_format='table' one of these days\n",
    "    pdf = data.pivot(index=[f1[\"col\"]], columns=f0[\"col\"])\n",
    "    pdf.columns = pdf.columns.get_level_values(1)\n",
    "    pdf = pdf.reset_index()\n",
    "    #print(data)\n",
    "    \n",
    "    source = alt.topo_feature(tjson_url, \"data\")\n",
    "    plot = alt.Chart(source).transform_lookup(\n",
    "        lookup = f\"properties.{geo_fname}\",\n",
    "        from_ = alt.LookupData(\n",
    "            data=pdf,\n",
    "            key=f1[\"col\"],\n",
    "            fields=f0[\"order\"]\n",
    "        ),\n",
    "    ).transform_fold(f0[\"order\"],as_=[f0[\"col\"],value_col]).mark_geoshape(stroke='white', strokeWidth=0.1).encode(\n",
    "        tooltip=[alt.Tooltip(f'properties.{ geo_fname}:N', title='maakond'),\n",
    "                alt.Tooltip(field=value_col, type='quantitative', title='osakaal', format=val_format)],\n",
    "        color=alt.Color(\n",
    "            field=value_col, type='quantitative',\n",
    "            scale=alt.Scale(scheme=\"reds\"),\n",
    "            legend=alt.Legend(format=val_format, title=None, orient='top-left'),\n",
    "        )\n",
    "    )\n",
    "    '''plot = alt.Chart(source).mark_geoshape(stroke='white', strokeWidth=0.1).transform_lookup(\n",
    "        lookup = f\"properties.{geo_fname}\",\n",
    "        from_ = alt.LookupData(\n",
    "            data=pdf,\n",
    "            key=f1[\"col\"],\n",
    "            fields=f0[\"order\"]\n",
    "        ),\n",
    "    ).transform_fold(f0[\"order\"],as_=[f0[\"col\"],value_col]).encode(\n",
    "        #tooltip=[alt.Tooltip(f'properties.{ geo_fname}:N', title='maakond'),\n",
    "        #        alt.Tooltip(f'{value_col}:Q', title='osakaal', format='.0%')],\n",
    "        color=alt.Color(\n",
    "            f'{value_col}:Q',\n",
    "            scale=alt.Scale(scheme=\"reds\"),\n",
    "            legend=alt.Legend(format=\".0%\", title=None, orient='top-left'),\n",
    "        ),\n",
    "        facet=alt.Facet(f'{f0[\"col\"]}:N')\n",
    "    )#.facet(f'{f0[\"col\"]}:N')'''\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@stk_plot('geoplot', data_format='longform', factor_columns=2, n_facets=(1,1), requires=[{'topo_feature':'pass'}], no_faceting=True, aspect_ratio=(4.0/3.0), no_question_facet=True, args={'separate_axes':'bool'})\n",
    "def geoplot(data, topo_feature, value_col='value', facets=[], val_format='.2f', tooltip=[],\n",
    "                separate_axes=False, outer_factors=[], outer_colors={}, value_range=None):\n",
    "    f0 = facets[0]\n",
    "\n",
    "    json_url, json_meta, json_col = topo_feature\n",
    "    if json_meta == 'geojson':\n",
    "        source = alt.Data(url=json_url, format=alt.DataFormat(property='features',type='json'))\n",
    "    else:\n",
    "        source = alt.topo_feature(json_url, json_meta)\n",
    "\n",
    "    lmi,lma = data[value_col].min(),data[value_col].max() \n",
    "    mi, ma = value_range if value_range and not separate_axes else (lmi,lma)\n",
    "    \n",
    "    # Only show maximum on legend if min and max too close together\n",
    "    legend_vals = [lmi,lma] if (lma-lmi)/(ma-mi) > 0.5 else [lma]\n",
    "    rel_range = [(lmi-mi)/(ma-mi), (lma-mi)/(ma-mi)]\n",
    "\n",
    "    ofv = data[outer_factors[0]].iloc[0] if outer_factors else None\n",
    "    # If colors provided, create a gradient based on that\n",
    "    if (outer_factors and outer_colors and  \n",
    "        data[outer_factors[0]].nunique() == 1 and\n",
    "        ofv in outer_colors):\n",
    "        \n",
    "        grad = gradient_from_color(outer_colors[ofv],range=rel_range)\n",
    "        scale = { 'domain': [lmi,lma], 'range': grad}\n",
    "    else: # Blues for pos, reds for neg, redblue for both\n",
    "\n",
    "        # If axis spans both directions\n",
    "        dmax = max(-mi,ma)\n",
    "        if mi<0.0 and ma>0.0: rel_range = [lmi/dmax, lma/dmax] # Spans both sides, so scale by dmax\n",
    "        elif ma<0.0: rel_range = [-rel_range[1], rel_range[0]] # Use negative part i.e. red scale\n",
    "        \n",
    "        grad = gradient_subrange(redblue_gradient, 11, range=rel_range)\n",
    "        scale = { 'domain': [lmi,lma], 'range': grad}\n",
    "        \n",
    "        # if mi<0 and ma>0: scale = { 'scheme':'redblue', 'domainMid':0, 'domainMin':-dmax, 'domainMax':dmax, 'rangeMax': 0.1 }\n",
    "        # elif ma<0: scale = { 'scheme': 'reds', 'reverse': True }#, 'domainMin': 0, 'domainMax':dmax }\n",
    "        # else: scale = { 'scheme': 'blues' }#, 'domainMin': 0, 'domainMax':dmax }\n",
    "\n",
    "    plot = alt.Chart(source).mark_geoshape(stroke='white', strokeWidth=0.1).transform_lookup(\n",
    "        lookup = f\"properties.{json_col}\",\n",
    "        from_ = alt.LookupData(\n",
    "            data=data,\n",
    "            key=f0[\"col\"],\n",
    "            fields=list(data.columns)\n",
    "        ),\n",
    "    ).encode(\n",
    "        tooltip=tooltip, #[alt.Tooltip(f'properties.{json_col}:N', title=f1[\"col\"]),\n",
    "                #alt.Tooltip(f'{value_col}:Q', title=value_col, format=val_format)],\n",
    "        color=alt.Color(\n",
    "            field=value_col, type='quantitative',\n",
    "            scale=alt.Scale(**scale), # To use color scale, consider switching to opacity for value\n",
    "            legend=alt.Legend(format=val_format, title=None, orient='top-left',gradientThickness=6, \n",
    "                                values=[lmi,lma]),\n",
    "        )\n",
    "    ).project('mercator')\n",
    "    return plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@stk_plot('geobest', data_format='longform', factor_columns=2, n_facets=(2,2), requires=[{},{'topo_feature':'pass'}], no_faceting=True,aspect_ratio=(4.0/3.0))\n",
    "def geobest(data, topo_feature, value_col='value', facets=[], val_format='.2f', tooltip=[], width=800):\n",
    "    f0, f1 = facets[0], facets[1]\n",
    "\n",
    "    json_url, json_meta, json_col = topo_feature\n",
    "    if json_meta == 'geojson':\n",
    "        source = alt.Data(url=json_url, format=alt.DataFormat(property='features',type='json'))\n",
    "    else:\n",
    "        source = alt.topo_feature(json_url, json_meta)\n",
    "\n",
    "    data = data.sort_values(value_col, ascending=False).drop_duplicates([f1['col']])\n",
    "    colormap = f0['colors']\n",
    "\n",
    "    plot = alt.Chart(source).mark_geoshape(stroke='white', strokeWidth=0.1).transform_lookup(\n",
    "        lookup = f\"properties.{json_col}\",\n",
    "        from_ = alt.LookupData(\n",
    "            data=data,\n",
    "            key=f1[\"col\"],\n",
    "            fields=list(data.columns)\n",
    "        ),\n",
    "    ).encode(\n",
    "        tooltip=tooltip, #[alt.Tooltip(f'properties.{json_col}:N', title=f1[\"col\"]),\n",
    "                #alt.Tooltip(f'{value_col}:Q', title=value_col, format=val_format)],\n",
    "        color=alt.Color(\n",
    "            field=f0['col'], type='nominal',\n",
    "            scale=f0['colors'],\n",
    "            legend=alt.Legend(orient='top',columns=estimate_legend_columns_horiz(f0[\"order\"],width)),\n",
    "        )\n",
    "    ).project('mercator')\n",
    "    return plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_metafile = '../data/master_meta.json'\n",
    "data_meta = read_json(data_metafile)\n",
    "    \n",
    "e2e_plot({\n",
    "    'res_col' : 'EKRE',\n",
    "    'factor_cols': ['electoral_district'],\n",
    "    'filter': {},\n",
    "    'plot': 'geoplot',\n",
    "    'internal_facet': True\n",
    "}, data_file, data_meta=data_meta,width=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_meta['structure']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "\n",
    "# Assuming ns is ordered by unique row values, find the split points\n",
    "def split_ordered(cvs):\n",
    "    if len(cvs.shape)==1: cvs = cvs[:,None]\n",
    "    unique_idxs = np.empty(len(cvs), dtype=np.bool_)\n",
    "    unique_idxs[:1] = False\n",
    "    unique_idxs[1:] = np.any(cvs[:-1, :] != cvs[1:, :], axis=-1)\n",
    "    return np.arange(len(unique_idxs))[unique_idxs]\n",
    "\n",
    "# Split a series of weights into groups of roughly equal sum\n",
    "# This algorithm is greedy and does not split values but it is fast and should be good enough for most uses\n",
    "def split_even_weight(ws, n):\n",
    "    cws = np.cumsum(ws)\n",
    "    cws = (cws/(cws[-1]/n)).astype('int')\n",
    "    return (split_ordered(cws)+1)[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "assert (split_even_weight([1,0,1,\n",
    "                           2,\n",
    "                           1.5,1,\n",
    "                           1.5],4) == np.array([3,4,6])).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def fd_mangle(vc, value_col, factor_col, n_points=10): \n",
    "    \n",
    "    vc = vc.sort_values(value_col)\n",
    "    \n",
    "    ws = np.ones(len(vc))\n",
    "    splits = split_even_weight(ws, n_points)\n",
    "    \n",
    "    ccodes, cats = vc[factor_col].factorize()\n",
    "    \n",
    "    ofreqs = np.stack([ np.bincount(g, weights=gw, minlength=len(cats))/gw.sum()\n",
    "                        for g,gw in zip(np.split(ccodes,splits),np.split(ws,splits)) ],axis=0)\n",
    "    \n",
    "    df = pd.DataFrame(ofreqs, columns=cats)\n",
    "    df['percentile'] = np.linspace(0,1,n_points)\n",
    "    return df.melt(id_vars='percentile',value_vars=cats,var_name=factor_col,value_name='density')\n",
    "\n",
    "@stk_plot('facet_dist', data_format='raw', factor_columns=3,aspect_ratio=(1.0/1.0), n_facets=(1,1), no_question_facet=True)\n",
    "def facet_dist(data, value_col='value',facets=[], tooltip=[], outer_factors=[]):\n",
    "    f0 = facets[0]\n",
    "    gb_cols = [ c for c in outer_factors if c is not None ] # There can be other extra cols (like labels) that should be ignored\n",
    "    ndata = gb_in_apply(data,gb_cols,cols=[value_col,f0[\"col\"]],fn=fd_mangle,value_col=value_col,factor_col=f0[\"col\"]).reset_index()\n",
    "    plot=alt.Chart(ndata).mark_area(interpolate='natural').encode(\n",
    "            x=alt.X(f\"percentile:Q\",axis=alt.Axis(format='%')),\n",
    "            y=alt.Y('density:Q',axis=alt.Axis(title=None, format = '%'),stack='normalize'),\n",
    "            tooltip = tooltip[1:],\n",
    "            color=alt.Color(f'{f0[\"col\"]}:N', scale=f0[\"colors\"], legend=alt.Legend(orient='top')),\n",
    "            #order=alt.Order('order:O')\n",
    "    )\n",
    "\n",
    "    return plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e2e_plot({\n",
    "    'res_col' : 'thermometer',\n",
    "    'factor_cols': ['party_preference'],  'filter': {},\n",
    "    'plot': 'facet_dist',\n",
    "    'internal_facet': True\n",
    "},data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "\n",
    "# Vectorized multinomial sampling. Should be slightly faster\n",
    "def vectorized_mn(prob_matrix):\n",
    "    s = prob_matrix.cumsum(axis=1)\n",
    "    s = s/s[:,-1][:,None]\n",
    "    r = np.random.rand(prob_matrix.shape[0])[:,None]\n",
    "    return (s < r).sum(axis=1)\n",
    "\n",
    "def linevals(vals, value_col, n_points, dim, cats, ccodes=None, ocols=None, boost_signal=True,gc=False, weights=None):\n",
    "    ws = weights if weights is not None else np.ones(len(vals))\n",
    "    \n",
    "    order = np.lexsort((vals,ccodes)) if dim and gc else np.argsort(vals)\n",
    "    splits = split_even_weight(ws[order], n_points)\n",
    "    aer = np.array([ g.mean() for g in np.split(vals[order],splits) ])\n",
    "    pdf = pd.DataFrame(aer, columns=[value_col])\n",
    "    \n",
    "    if dim:\n",
    "        # Find the frequency of each category in ccodes\n",
    "        osignal = np.stack([ np.bincount(g, weights=gw, minlength=len(cats))/gw.sum()\n",
    "                            for g,gw in zip(np.split(ccodes[order],splits),np.split(ws[order],splits)) ],axis=0)\n",
    "        \n",
    "        ref_p = osignal.mean(axis=0)+1e-10\n",
    "        np.random.seed(0) # So they don't change every re-render\n",
    "\n",
    "        signal = osignal + 1e-10 # So even if values are zero, log and vectorized_mn would work\n",
    "        if boost_signal: # Boost with K-L, leaving only categories that grew in probability boosted by how much they did\n",
    "            klv = signal*(np.log(signal/ref_p[None,:]))\n",
    "            signal = np.maximum(1e-10,klv)\n",
    "            pdf['kld'] = np.sum(klv,axis=1)\n",
    "\n",
    "        #pdf[dim] = cats[signal.apply(lambda r: np.random.multinomial(1,r/r.sum()).argmax() if r.sum()>0.0 else 0,axis=1)]\n",
    "        cat_inds = vectorized_mn(signal)\n",
    "        pdf[dim] = np.array(cats)[cat_inds]\n",
    "        pdf['probability'] = osignal[np.arange(len(cat_inds)),cat_inds]\n",
    "\n",
    "        #pdf[dim] = pdf[cats].idxmax(axis=1)\n",
    "        #pdf['weight'] = np.minimum(pdf[cats].max(axis=1),pdf['matches'])\n",
    "\n",
    "    pdf['pos'] = np.arange(0,1,1.0/len(pdf))\n",
    "    \n",
    "    if ocols is not None:\n",
    "        for iv in ocols.index:\n",
    "            pdf[iv] = ocols[iv]\n",
    "\n",
    "    return pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@stk_plot('ordered_population', data_format='raw', factor_columns=3, aspect_ratio=(1.0/1.0), plot_args={'group_categories':'bool'}, n_facets=(0,1), no_question_facet=True)\n",
    "def ordered_population(data, value_col='value', facets=[], tooltip=[], outer_factors=[], group_categories=False):\n",
    "    f0 = facets[0] if len(facets)>0 else None\n",
    "    \n",
    "    n_points, maxn = 200, 1000000\n",
    "    \n",
    "     # TODO: use weight if available. linevals is ready for it, just needs to be fed in. \n",
    "    \n",
    "    # Sample down to maxn points if exceeding that\n",
    "    if len(data)>maxn: data = data.sample(maxn,replace=False)\n",
    "    \n",
    "    data = data.sort_values(outer_factors)\n",
    "    vals = data[value_col].to_numpy()\n",
    "\n",
    "    if len(facets)>=1:\n",
    "        fcol = f0[\"col\"]\n",
    "        cat_idx, cats = pd.factorize(data[f0[\"col\"]])\n",
    "        cats = list(cats)\n",
    "    else:\n",
    "        fcol = None\n",
    "        cat_idx, cats = None, []\n",
    "        \n",
    "    if outer_factors:\n",
    "        \n",
    "        # This is optimized to not use pandas.groupby as it makes it about 2x faster - which is 2+ seconds with big datasets\n",
    "        \n",
    "        # Assume data is sorted by outer_factors, split vals into groups by them\n",
    "        ofids = np.stack([ data[f].cat.codes.values for f in outer_factors ],axis=1)\n",
    "        splits = split_ordered(ofids)        \n",
    "        groups = np.split(vals,splits)\n",
    "        cgroups = np.split(cat_idx,splits) if len(facets)>=1 else groups\n",
    "        \n",
    "        # Perform the equivalent of groupby\n",
    "        ocols = data.iloc[[0]+list(splits)][outer_factors]\n",
    "        tdf = pd.concat([linevals(g,value_col=value_col,dim=fcol, ccodes=gc, cats=cats, n_points=n_points,ocols=ocols.iloc[i,:],gc=group_categories) \n",
    "                        for i,(g,gc) in enumerate(zip(groups,cgroups))])\n",
    "\n",
    "        #tdf = data.groupby(outer_factors,observed=True).apply(linevals,value_col=value_col,dim=fcol,cats=cats,n_points=n_points,gc=group_categories,include_groups=False).reset_index()\n",
    "    else:\n",
    "        tdf = linevals(vals,value_col=value_col,dim=fcol,ccodes=cat_idx,cats=cats,n_points=n_points, gc=group_categories)\n",
    "        #tdf = linevals(data,value_col=value_col,cats=cats,dim=fcol,n_points=n_points,gc=group_categories)\n",
    "        \n",
    "    #if boost_signal:\n",
    "    #    tdf['matches'] = np.minimum(tdf['matches'],tdf['kld']/tdf['kld'].quantile(0.75))\n",
    "\n",
    "    base = alt.Chart(tdf).encode(\n",
    "        x=alt.X('pos:Q',\n",
    "            title=\"\",\n",
    "            axis=alt.Axis(\n",
    "                labels=False,\n",
    "                ticks=False,\n",
    "                #grid=False\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    #selection = alt.selection_multi(fields=[dim], bind='legend')\n",
    "    line = base.mark_circle(size=10).encode(\n",
    "        y=alt.Y(f\"{value_col}:Q\",impute={'value':None}, title='', axis=alt.Axis(grid=True)),\n",
    "        #opacity=alt.condition(selection, alt.Opacity(\"matches:Q\",scale=None), alt.value(0.1)),\n",
    "        color=alt.Color(\n",
    "            field=f0[\"col\"], type='nominal',\n",
    "            sort=f0[\"order\"],\n",
    "            scale=f0[\"colors\"]\n",
    "            ) if len(facets)>=1 else alt.value('red'),\n",
    "        tooltip=tooltip+([alt.Tooltip('probability:Q',format='.1%',title='category prob.')] if len(facets)>=1 else [])\n",
    "    )#.add_selection(selection)\n",
    "\n",
    "\n",
    "    rule = alt.Chart().mark_rule(color='red', strokeDash=[2, 3]).encode(\n",
    "        y=alt.Y('mv:Q')\n",
    "    ).transform_joinaggregate(\n",
    "        mv = f'mean({value_col}):Q',\n",
    "        groupby=outer_factors\n",
    "    )\n",
    "\n",
    "    plot = alt.layer(\n",
    "        rule,\n",
    "        line,\n",
    "        data=tdf,\n",
    "    )\n",
    "    return plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e2e_plot({\n",
    "    'res_col' : 'thermometer',\n",
    "    'factor_cols': ['party_preference'],  'filter': {},\n",
    "    'plot': 'ordered_population',\n",
    "    #'plot_args': {'group_categories':True},\n",
    "    'internal_facet': True\n",
    "},data_file,width=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@stk_plot('marimekko', data_format='longform', draws=False, group_sizes=True, args={'separate':'bool'}, n_facets=(2,2), priority=55)\n",
    "def marimekko(data, value_col='value', facets=[], val_format='%', width=800, tooltip=[], outer_factors=[], separate=False, translate=None):\n",
    "    f0, f1 = facets[0], facets[1]\n",
    "    tf = translate if translate else (lambda s: s)\n",
    "\n",
    "    xcol, ycol, ycol_scale, yorder = f1[\"col\"], f0[\"col\"], f0[\"colors\"], list(reversed(f0[\"order\"]))\n",
    "\n",
    "    # Fill in missing values with zero\n",
    "    mdf = pd.DataFrame(it.product(f1['order'],f0['order'],*[data[c].unique() for c in outer_factors]),columns=[xcol,ycol]+outer_factors)\n",
    "    data = mdf.merge(data,on=[xcol,ycol]+outer_factors,how='left').fillna({value_col:0,'group_size':1})\n",
    "    data[xcol] = pd.Categorical(data[xcol],f1['order'],ordered=True)\n",
    "    data[ycol] = pd.Categorical(data[ycol],yorder,ordered=True)\n",
    "\n",
    "    data['w'] = data['group_size']*data[value_col]\n",
    "    data.sort_values([ycol,xcol],ascending=[True,False],inplace=True)\n",
    "\n",
    "    if separate: # Split and center each ycol group so dynamics can be better tracked for all of them\n",
    "        ndata = data.groupby(outer_factors+[xcol],observed=False)[[ycol,value_col,'w']].apply(lambda df: pd.DataFrame({ ycol: df[ycol], 'yv': df['w']/df['w'].sum(), 'w': df['w']})).reset_index()\n",
    "        ndata = ndata.merge(ndata.groupby(outer_factors + [ycol],observed=True)['yv'].max().rename('ym').reset_index(),on=outer_factors + [ycol]).fillna({'ym':0.0})\n",
    "        ndata = ndata.groupby(outer_factors+[xcol],observed=False)[[ycol,'w','yv','ym']].apply(lambda df: pd.DataFrame({ ycol: df[ycol], 'yv': df['yv'], 'w': df['w'].sum(),\n",
    "                                                                                                                        'y1': (df['ym'].cumsum()- df['ym']/2 - df['yv']/2)/df['ym'].sum(),\n",
    "                                                                                                                        'y2': (df['ym'].cumsum()- df['ym']/2 + df['yv']/2)/df['ym'].sum(), })).reset_index()\n",
    "    else: # Regular marimekko\n",
    "        ndata = data.groupby(outer_factors+[xcol],observed=False)[[ycol,value_col,'w']].apply(lambda df: pd.DataFrame({ ycol: df[ycol], 'w': df['w'].sum(),\n",
    "                                                                                                                        'yv': df['w']/df['w'].sum(), \n",
    "                                                                                                                        'y2': df['w'].cumsum()/df['w'].sum()})).reset_index()\n",
    "        ndata['y1'] = ndata['y2']-ndata['yv']\n",
    "    \n",
    "    ndata = ndata.groupby(outer_factors+[ycol],observed=False)[[xcol,'yv','y1','y2','w']].apply(lambda df: pd.DataFrame({ xcol: df[xcol], 'xv': df['w']/df['w'].sum(), 'x2': df['w'].cumsum()/df['w'].sum(), 'yv':df['yv'], 'y1':df['y1'], 'y2':df['y2']})).reset_index()\n",
    "    ndata['x1'] = ndata['x2']-ndata['xv']\n",
    "\n",
    "    ndata['tprop'] = ndata['xv']*ndata['yv'] # Overall proportion\n",
    "\n",
    "    ndata['xmid'] = (ndata['x1']+ndata['x2'])/2\n",
    "    ndata['text'] = ndata[xcol].astype(str)\n",
    "    #ndata['text'] = list(map(lambda x: x[0]+' '+x[1],zip(ndata[xcol].astype(str),ndata['xv'].round(2).astype(str))))\n",
    "    ndata.loc[ndata[ycol]!=yorder[0],'text'] = ''\n",
    "\n",
    "    # Hack an axis title to those text labels. Not pretty but it works\n",
    "    ndata['text2'] = ''\n",
    "    ndata.iloc[0,-1] = xcol\n",
    "\n",
    "    #selection = alt.selection_point(fields=[yvar], bind=\"legend\"\n",
    "    \n",
    "    STROKE = 0.25\n",
    "    base = alt.Chart(ndata)\n",
    "    plot = base.mark_rect(\n",
    "            strokeWidth=STROKE,\n",
    "            stroke=\"white\",\n",
    "            xOffset=STROKE / 2,\n",
    "            x2Offset=STROKE / 2,\n",
    "            yOffset=STROKE / 2,\n",
    "            y2Offset=STROKE / 2,\n",
    "        ).encode(\n",
    "            x=alt.X(\n",
    "                \"x1:Q\",\n",
    "                axis=alt.Axis(\n",
    "                    zindex=1, format=\"%\", grid=False,\n",
    "                    orient='top', title=None\n",
    "                ),\n",
    "                scale=alt.Scale(domain=[0, 1]),\n",
    "            ),\n",
    "            x2=alt.X2(\"x2:Q\"),\n",
    "            y=alt.Y(\n",
    "                \"y1:Q\",\n",
    "                axis=alt.Axis(\n",
    "                    zindex=1, format=\"%\", title='', grid=False, labels=not separate\n",
    "                    ),  \n",
    "                scale=alt.Scale(domain=[0, 1])\n",
    "            ),\n",
    "            y2=alt.Y2(\"y2:Q\"),\n",
    "            color=alt.Color(\n",
    "                f\"{ycol}:N\",\n",
    "                legend=(alt.Legend(orient='top',titleAlign='center',titleOrient='left',columns=estimate_legend_columns_horiz(f0['order'],width,f0['col'])) \n",
    "                        if len(f0['order'])<=5 else alt.Legend(orient='right')), # This plot needs the vertical space to be useful for 5+ cats\n",
    "                #legend=alt.Legend(orient='top',columns=estimate_legend_columns_horiz(f0['order'],width)),\n",
    "                #legend=alt.Legend(orient='top',titleOrient='left', symbolStrokeWidth=0), #title=f\"{yvar}\"),\n",
    "                scale=ycol_scale,\n",
    "            ),\n",
    "            tooltip=[\n",
    "                alt.Tooltip(field=ycol),\n",
    "                alt.Tooltip(field=xcol),\n",
    "                alt.Tooltip(\"yv:Q\", title=tf('Of column'), format='.1%' ),\n",
    "                alt.Tooltip(\"tprop:Q\", title=tf('Of population'), format='.1%'),\n",
    "            ]+tooltip[3:]\n",
    "            #opacity=alt.condition(selection, alt.value(1), alt.value(0.3)),\n",
    "        )\n",
    "    text = base.mark_text(\n",
    "        baseline='top', align='center', dy=3,\n",
    "        fontSize=14, color='#808495' # Streamlit default theme, which we use for the app\n",
    "    ).encode(\n",
    "        text=alt.Text(f'text:N'),\n",
    "        x=alt.X('xmid:Q'),y=alt.Y('y1:Q'),\n",
    "        tooltip=[alt.Tooltip('xv:Q',title=tf('%s size') % xcol, format='.1%')]\n",
    "    )\n",
    "\n",
    "    custom_title = base.mark_text(\n",
    "        align=\"center\",\n",
    "        baseline=\"top\",     # Position text at the bottom\n",
    "        fontSize=14, color='#808495',\n",
    "        #font='\"Source Sans Pro\", sans-serif',\n",
    "        fontWeight=200,\n",
    "        dy=20\n",
    "    ).encode(\n",
    "        text=alt.Text(f'text2:N'),\n",
    "        #x=alt.datum(0),     # Center the title horizontally\n",
    "        y=alt.datum(0)      # Anchor to the bottom\n",
    "    )\n",
    "    \n",
    "    return plot + text + custom_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e2e_plot({\n",
    "    'res_col' : 'trust',\n",
    "    'factor_cols': ['question','party_preference'],\n",
    "    'filter': {},\n",
    "    #'plot_args': {'separate':True},\n",
    "    'plot': 'marimekko',\n",
    "    'internal_facet': True,\n",
    "},data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test convert_res\n",
    "e2e_plot({\n",
    "    'res_col' : 'age_group',\n",
    "    'factor_cols': ['gender'],\n",
    "    'filter': {},\n",
    "    'plot': 'boxplots',\n",
    "    'internal_facet': True,\n",
    "    'convert_res': 'continuous'\n",
    "},data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test replace_question and num_values\n",
    "e2e_plot({\n",
    "    'res_col' : 'valitsus',\n",
    "    'factor_cols': ['party_preference','age_group'],\n",
    "    'filter': {},\n",
    "    'convert_res': 'continuous',\n",
    "    'num_values': [0,0,0,1,1],\n",
    "    'value_name': 'Pr[valitsus==Agree]',\n",
    "    'value_format': '.0%',\n",
    "    'plot': 'lines_hdi',\n",
    "    'internal_facet': True,\n",
    "}, data_file, width=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test labels\n",
    "data_file = '../samples/m_bootstrap.parquet'\n",
    "data_metafile = '../../salk_internal_package/data/master_meta.json'\n",
    "if data_metafile:\n",
    "    data_meta = read_json(data_metafile)\n",
    "e2e_plot({\n",
    "    'res_col' : 'trust',\n",
    "    'factor_cols': ['gender','age_group'],\n",
    "    'filter': {},\n",
    "    'plot': 'likert_bars',\n",
    "    'internal_facet': True\n",
    "}, data_file, width=800, data_meta=data_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "salk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
