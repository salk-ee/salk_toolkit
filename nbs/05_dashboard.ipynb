{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dashboard\n",
    "> Modular pieces for streamlit dashboards\n",
    "> All of this is meant to be run in a streamlit environment and is likely to fail elsewhere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "import json, os, csv, re, time, types, inspect, psutil\n",
    "import itertools as it\n",
    "from collections import defaultdict\n",
    "from contextlib import AbstractContextManager\n",
    "from abc import ABC, abstractmethod\n",
    "from copy import deepcopy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import datetime as dt\n",
    "\n",
    "from typing import List, Tuple, Dict, Union, Optional\n",
    "\n",
    "import altair as alt\n",
    "import s3fs, polib\n",
    "import __main__ # to get name of py file\n",
    "\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "\n",
    "from salk_toolkit.utils import *\n",
    "from salk_toolkit.io import *\n",
    "from salk_toolkit.pp import e2e_plot\n",
    "\n",
    "import streamlit as st\n",
    "from streamlit_option_menu import option_menu\n",
    "from streamlit_dimensions import st_dimensions\n",
    "import streamlit_authenticator as stauth\n",
    "import libsql_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_plot_width(key):\n",
    "    wobj = st_dimensions(key=key) or { 'width': 800 } # Can return none so handle that\n",
    "    return min(800,int(0.8*wobj['width'])) # Needs to be adjusted down  to leave margin for plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def update_manifest(fname):\n",
    "    # Create manifests directory if it doesn't exist\n",
    "    os.makedirs('manifests', exist_ok=True)\n",
    "    \n",
    "    # Get name of main python file without extension\n",
    "    main_name = os.path.splitext(os.path.basename(__main__.__file__))[0]\n",
    "    \n",
    "    # Create manifest json file\n",
    "    manifest_path = os.path.join('manifests', f'{main_name}.json')\n",
    "    if os.path.exists(manifest_path):\n",
    "        with open(manifest_path,'r') as f:\n",
    "            manifest = json.load(f)\n",
    "        if 'files' not in manifest: manifest['files'] = []\n",
    "    else:\n",
    "        manifest = {\n",
    "            'id': main_name,\n",
    "            'app': main_name + '.py',\n",
    "            'requirements': 'requirements.txt',\n",
    "            'files': ['deployment.json'] # TODO: This system should be rethought\n",
    "        }\n",
    "    \n",
    "    if fname not in manifest['files']:\n",
    "        manifest['files'].append(fname)\n",
    "        with open(manifest_path,'w') as f:\n",
    "            json.dump(manifest, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "# Open either a local or an s3 file\n",
    "def open_fn(fname, *args, s3_fs=None, **kwargs):\n",
    "    #update_manifest(fname) # Actually these tend to be the files we want to be in S3\n",
    "    if fname[:3] == 's3:':\n",
    "        if s3_fs is None: s3_fs = s3fs.S3FileSystem(anon=False)\n",
    "        return s3_fs.open(fname,*args,**kwargs)\n",
    "    else:\n",
    "        return open(fname,*args,**kwargs)\n",
    "    \n",
    "def exists_fn(fname, *args, s3_fs=None, **kwargs):\n",
    "    if fname[:3] == 's3:':\n",
    "        if s3_fs is None: s3_fs = s3fs.S3FileSystem(anon=False)\n",
    "        return s3_fs.exists(fname,*args,**kwargs)\n",
    "    else:\n",
    "        return os.path.exists(fname,*args,**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "# ttl=None - never expire. Makes sense for potentially big data files\n",
    "@st.cache_resource(show_spinner=False,ttl=None)\n",
    "def read_annotated_data_lazy_cached(data_source,**kwargs):\n",
    "    print(f\"Reading lazy data from {data_source}\")\n",
    "    return read_annotated_data_lazy(data_source,**kwargs)\n",
    "\n",
    "# Load json uncached - useful for admin pages\n",
    "def load_json(fname, _s3_fs=None, **kwargs):\n",
    "    with open_fn(fname,'r',s3_fs=_s3_fs,encoding='utf8') as jf:\n",
    "        return json.load(jf)\n",
    "\n",
    "# This is cached very short term (1 minute) to avoid downloading it on every page change\n",
    "# while still allowing users to be added / changed relatively responsively\n",
    "@st.cache_data(show_spinner=False,ttl=60)\n",
    "def load_json_cached(fname, _s3_fs=None, **kwargs):\n",
    "    return load_json(fname,_s3_fs,**kwargs)\n",
    "\n",
    "# For saving json back \n",
    "def save_json(d, fname, _s3_fs=None, **kwargs):\n",
    "    with open_fn(fname,'w',s3_fs=_s3_fs,encoding='utf8') as jf:\n",
    "        json.dump(d,jf,indent=2,ensure_ascii=False)\n",
    "        \n",
    "def alias_file(fname, file_map):\n",
    "    if fname[:3]!='s3:' and fname in file_map and not os.path.exists(fname):\n",
    "        #print(f\"Redirecting {fname} to {file_map[fname]}\")\n",
    "        return file_map[fname]\n",
    "    else: return fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def log_event(event, uid, path, s3_fs=None):\n",
    "    timestamp = dt.datetime.now(dt.timezone.utc).strftime('%d-%m-%Y, %H:%M:%S')\n",
    "\n",
    "    if not exists_fn(path, s3_fs=s3_fs): # If file not present, create it\n",
    "        print(f\"Log file {path} not found, creating it\")\n",
    "        open_fn(path,'w',s3_fs=s3_fs).close()\n",
    "\n",
    "    # Just append the row to the file    \n",
    "    with open_fn(path,'a',s3_fs=s3_fs) as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([timestamp, event, uid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "\n",
    "st_wrap_list = ['write','markdown','title','header','subheader','caption','text','divider',\n",
    "                'button','download_button','link_button','checkbox','toggle','radio','selectbox',\n",
    "                'multiselect','slider','select_slider','text_input','number_input','text_area',\n",
    "                'date_input','time_input','file_uploader','camera_input','color_picker', 'popover',\n",
    "                'spinner', 'info', 'error', 'warning', 'success', 'pills' ]\n",
    "\n",
    "# def debugf(f,*args,**kwargs):\n",
    "#     print(f.__name__,args,kwargs)\n",
    "#     return f(*args,**kwargs)\n",
    "\n",
    "# Some keyword arguments can be translated\n",
    "def transform_kws(kws,tfo):\n",
    "    if 'context' in kws: del kws['context']\n",
    "    if 'format_func' in kws: \n",
    "        ff = kws['format_func']\n",
    "        kws['format_func'] = lambda s: tfo.tf(ff(s))\n",
    "    if 'placeholder' in kws: kws['placeholder'] = tfo.tf(kws['placeholder'])\n",
    "    return kws\n",
    "\n",
    "# wrap the first parameter of streamlit function with self.translate\n",
    "# has to be a separate function instead of in a for loop for scoping reasons\n",
    "def wrap_st_with_translate(base, fd, tfo):\n",
    "\n",
    "    if isinstance(fd, str): fd = { 'name': fd, 'args': ['str'] }\n",
    "    func = getattr(base,fd['name'])\n",
    "\n",
    "    # If format_func is a parameter, overwrite it with the translate function\n",
    "    kw_defaults = ({ 'format_func': tfo.tf } \n",
    "            if 'format_func' in inspect.signature(func).parameters \n",
    "            else {})\n",
    "\n",
    "    tfs = { 'str': lambda c: (lambda s: tfo.tf(s,context=c)), \n",
    "            'list': lambda c: (lambda l: [tfo.tf(s,context=c) for s in l]) }\n",
    "    return lambda *args, **kwargs: func( # debugf(func,\n",
    "        *[tfs[tt](kwargs.get('context'))(args[i]) for i,tt in enumerate(fd['args'])],\n",
    "        *args[len(fd['args']):],**{**kw_defaults,**transform_kws(kwargs,tfo)})\n",
    "\n",
    "# A class that wraps another context manager\n",
    "class ContextManagerWrapper(AbstractContextManager):\n",
    "    def __init__(self, obj):\n",
    "        self.obj = obj\n",
    "    def __enter__(self):\n",
    "        return self.obj.__enter__()\n",
    "    def __exit__(self, *args):\n",
    "        self.obj.__exit__(*args)\n",
    "\n",
    "def wrap_all_st_functions(base, tfo, to=None):\n",
    "    if to is None:\n",
    "        to = ContextManagerWrapper(base)\n",
    "    \n",
    "    for fd in st_wrap_list:\n",
    "        fn = fd['name'] if isinstance(fd, dict) else fd\n",
    "        if not hasattr(st,fn): continue\n",
    "        setattr(to, fn, wrap_st_with_translate(base,fd,tfo))\n",
    "    \n",
    "    # Container creators need to be wrapped recursively\n",
    "    setattr(to,'tabs',lambda *args,**kwargs: \n",
    "            tuple( wrap_all_st_functions(c,tfo) \n",
    "                for c in wrap_st_with_translate(base,{'name':'tabs', 'args':['list']},tfo)(*args,**kwargs)))\n",
    "    setattr(to,'columns',lambda *args,**kwargs: \n",
    "            tuple( wrap_all_st_functions(c,tfo) \n",
    "                    for c in base.columns(*args,**kwargs)))\n",
    "\n",
    "    setattr(to,'expander',lambda *args,**kwargs: \n",
    "            wrap_all_st_functions(wrap_st_with_translate(base,'expander',tfo)(*args,**kwargs),tfo))\n",
    "    setattr(to,'container',lambda *args,**kwargs: \n",
    "            wrap_all_st_functions(base.container(*args,**kwargs),tfo))\n",
    "\n",
    "    return to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def default_translate(s,**kwargs):\n",
    "    return (s[0].upper() + s[1:]).replace('_',' ') if isinstance(s,str) and len(s)>0 else s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "\n",
    "# A function that automatically updates the pot file with untranslated strings\n",
    "def po_template_updater(pot_file = None):\n",
    "    if pot_file is None:\n",
    "        bname = os.path.splitext(os.path.basename(__main__.__file__))[0]\n",
    "        pot_file = f'locale/{bname}.pot'\n",
    "\n",
    "    if os.path.exists(pot_file):\n",
    "        po  = polib.pofile(pot_file)\n",
    "        tdc = defaultdict(set)\n",
    "        for entry in po:\n",
    "            context = entry.msgctxt or ''\n",
    "            tdc[context].add(entry.msgid)\n",
    "    else:\n",
    "        po = polib.POFile()\n",
    "        po.metadata = {\n",
    "            'Project-Id-Version': '1.0',\n",
    "            'Report-Msgid-Bugs-To': 'tarmo@salk.com',\n",
    "            'MIME-Version': '1.0',\n",
    "            'Content-Type': 'text/plain; charset=utf-8',\n",
    "            'Content-Transfer-Encoding': '8bit',\n",
    "        }\n",
    "        tdc = defaultdict(set)\n",
    "    update_manifest(pot_file)\n",
    "\n",
    "    def translate(s,**kwargs):\n",
    "        ctx = kwargs.get('context') or ''\n",
    "        if isinstance(s,str) and s not in tdc[ctx]:\n",
    "            po.append(polib.POEntry(msgid=s,msgstr=default_translate(s), \n",
    "                                    **{'msgctxt': kwargs.get('context'), 'comment': kwargs.get('comment')}))\n",
    "            po.save(pot_file)\n",
    "            tdc[ctx].add(s)\n",
    "        return s\n",
    "    \n",
    "    return translate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "\n",
    "def translate_fn_from_po(po_file):\n",
    "    po = polib.pofile(po_file)\n",
    "    td = { entry.msgid: entry.msgstr for entry in po }\n",
    "    return lambda s, **kwargs: td.get(s,s)\n",
    "\n",
    "def load_translate(translate, cc_translations={}):\n",
    "\n",
    "    if translate is None: return default_translate\n",
    "    elif callable(translate): return translate\n",
    "    elif isinstance(translate,dict): return lambda s, **kwargs: translate.get(s,s)\n",
    "    elif isinstance(translate,str):\n",
    "        if (translate not in cc_translations or \n",
    "            (translate in cc_translations and cc_translations[translate] is None)):\n",
    "            return default_translate\n",
    "        if os.path.exists(translate):\n",
    "            ext = os.path.splitext(translate)[1]\n",
    "            if ext == '.po' or ext == '.pot':\n",
    "                return translate_fn_from_po(translate)\n",
    "            elif ext == '.json':\n",
    "                td = load_json_cached(translate)\n",
    "                return lambda s, **kwargs: td.get(s,s)\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown translation file type: {ext}\")\n",
    "        elif translate in cc_translations: # country code\n",
    "            return cc_translations[translate]\n",
    "        else:\n",
    "            raise ValueError(f\"Translation file not found: {translate}\")\n",
    "\n",
    "@st.cache_resource(show_spinner=False,ttl=3600)\n",
    "def load_po_translations():\n",
    "    # Get base filename from __main__ \n",
    "    bname = os.path.splitext(os.path.basename(__main__.__file__))[0]\n",
    "    \n",
    "    # Find all locale subdirectories\n",
    "    translations = { 'en': None } # English is the default\n",
    "    if os.path.exists('locale'):\n",
    "        for country_code in os.listdir('locale'):\n",
    "            po_path = f'locale/{country_code}/{bname}.po'\n",
    "            if os.path.exists(po_path):\n",
    "                update_manifest(po_path)\n",
    "                translations[country_code] = translate_fn_from_po(po_path)\n",
    "                \n",
    "    return translations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after 'if' statement on line 17 (3785545687.py, line 18)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 18\u001b[0;36m\u001b[0m\n\u001b[0;31m    self.log_path = alias_file(logfile, self.filemap) if logfile else 'log.csv'\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'if' statement on line 17\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "\n",
    "# Main dashboard wrapper - WIP\n",
    "class SalkDashboardBuilder:\n",
    "\n",
    "    def __init__(self, data_source, auth_conf=None, logfile=None, groups=['guest','user','admin'], org_whitelist=None, \n",
    "                public=False, default_lang='en', plot_caching=True, header_fn=None, footer_fn=None):\n",
    "        \n",
    "        # Allow deployment.json to redirect files from local to s3 if local missing (i.e. in deployment scenario)\n",
    "        if os.path.exists('./deployment.json'):\n",
    "            dep_meta = load_json_cached('./deployment.json')\n",
    "            self.filemap = dep_meta.get('files',{})\n",
    "            #data_source = alias_file(data_source,self.filemap)\n",
    "            auth_conf = alias_file(auth_conf,self.filemap) if auth_conf else None # Only needed for old login\n",
    "        else: self.filemap = {}\n",
    "        \n",
    "        self.log_path = alias_file(logfile, self.filemap) if logfile else 'log.csv'\n",
    "        self.s3fs = s3fs.S3FileSystem(anon=False) # Initialize s3 access. Key in secrets.toml\n",
    "        self.data_source = data_source\n",
    "        self.public = public\n",
    "        self.pages = []\n",
    "        self.sb_info = st.sidebar.empty()\n",
    "        self.info = st.empty()\n",
    "        self.plot_caching = plot_caching\n",
    "        self.header_fn,self.footer_fn = header_fn,footer_fn # Header and footer functions\n",
    "\n",
    "        # Current page name\n",
    "        self.page_name = None\n",
    "        \n",
    "        # Set up translation\n",
    "        self.pot_updater = po_template_updater()\n",
    "        self.cc_translations = load_po_translations()\n",
    "        self.default_lang = default_lang\n",
    "        login_lang_choice = st.sidebar.empty()\n",
    "\n",
    "        #print(\"LANG\",st.session_state.get('lang'),st.session_state.get('chosen_lang'),st.session_state.get('login_lang'))\n",
    "\n",
    "        # If only one language is available, set it as the one in use\n",
    "        if len(self.cc_translations) == 1: \n",
    "            st.session_state['lang'] = next(iter(self.cc_translations.keys()))\n",
    "\n",
    "        # Don't ask for language in public dashboards\n",
    "        if not public and not st.secrets.get('auth',{}).get('use_oauth'):  \n",
    "            # This for language select during login page, which is unnecessar\n",
    "            # Set language from session state if present \n",
    "            if st.session_state.get('lang'): \n",
    "                self.set_translate(st.session_state.get('lang'))\n",
    "            else: # Alternatively (if on login page) - show the choice at the top of the sidebar\n",
    "                # This is messy because streamlit is ... not great at this kind of thing\n",
    "                opts = [self.default_lang] + [l for l in self.cc_translations.keys() if l != self.default_lang]\n",
    "\n",
    "                # chosen_lang is a temporary variable to store the chosen language on the login page\n",
    "                clang = st.session_state.get('chosen_lang') or self.default_lang\n",
    "                self.set_translate(clang)\n",
    "                def set_login_lang():\n",
    "                    st.session_state['chosen_lang'] = st.session_state['login_lang']\n",
    "\n",
    "                ind = opts.index(st.session_state.get('login_lang',self.default_lang)) # FIXES lang not updating\n",
    "                lang = login_lang_choice.selectbox(self.tf(\"Language:\",context='ui'), opts, \n",
    "                                                    index=ind, on_change=set_login_lang, key='login_lang')\n",
    "                if lang != clang: self.set_translate(lang)\n",
    "        else:\n",
    "            self.set_translate(self.default_lang)            \n",
    "            \n",
    "        self.p_widths = {}\n",
    "        \n",
    "        # Set up authentication\n",
    "        with st.spinner(self.tf(\"Setting up authentication...\",context='ui')):\n",
    "            if st.secrets.get('auth',{}).get('use_oauth'):\n",
    "                self.uam = FronteggAuthenticationManager(groups, org_whitelist=org_whitelist,\n",
    "                                                info=self.info, logger=self.log_event, languages=self.cc_translations, \n",
    "                                                translate_func=lambda t: self.tf(t,context='ui'))\n",
    "            else:\n",
    "                self.uam = StreamlitAuthenticationManager(auth_conf, groups, org_whitelist=org_whitelist,\n",
    "                                                s3_fs=self.s3fs, info=self.info, logger=self.log_event, languages=self.cc_translations,\n",
    "                                                translate_func=lambda t: self.tf(t,context='ui'))\n",
    "\n",
    "        if not public:\n",
    "            self.uam.login_screen()\n",
    "        \n",
    "        # TODO: language handling is overengineered. Remove the complexity\n",
    "        if self.authenticated and isinstance(self.uam,StreamlitAuthenticationManager):\n",
    "            login_lang_choice.empty()\n",
    "\n",
    "            # If user has chosen a language on the login page\n",
    "            if st.session_state.get('chosen_lang'): \n",
    "                self.set_translate(st.session_state['chosen_lang'],remember=True) # Make it persistent\n",
    "                st.session_state['chosen_lang'] = None # Only do this once, at login\n",
    "\n",
    "                # If the value differs from the user's current language, update it\n",
    "                if st.session_state['lang'] != self.user['lang']:\n",
    "                    self.uam.users[st.session_state['username']]['lang'] = st.session_state['lang']\n",
    "                    self.uam.update_user(st.session_state['username'])\n",
    "            # Load language from user's profile if present\n",
    "            elif (not st.session_state.get('lang') and self.user.get('lang') \n",
    "                and self.user['lang'] in self.cc_translations):\n",
    "                self.set_translate(self.user['lang'],remember=True)\n",
    "        else:\n",
    "            self.set_translate(self.user.get('lang'),remember=True)\n",
    "            \n",
    "\n",
    "        wrap_all_st_functions(st, self, to=self)\n",
    "        self.sidebar = wrap_all_st_functions(st.sidebar, self)    \n",
    "        \n",
    "    def set_translate(self,lang,remember=False):\n",
    "        if lang is None or lang not in self.cc_translations: lang = self.default_lang\n",
    "        translate = load_translate(lang, self.cc_translations)\n",
    "        self.tf = lambda s,**kwargs: translate(self.pot_updater(s,**kwargs))\n",
    "        if remember: st.session_state['lang'] = lang\n",
    "\n",
    "\n",
    "    # Get the pandas dataframe with given columns\n",
    "    def get_df(self,columns=None):\n",
    "        if columns is None: q = self.ldf\n",
    "        else: q = self.ldf.select(columns)\n",
    "        return fix_df_with_meta(q.collect().to_pandas(),self.meta)\n",
    "    \n",
    "    # For backwards compatibility - this is very inefficient\n",
    "    @property\n",
    "    def df(self):\n",
    "        warn(\"sdb.df is very inefficient. Use sdb.get_df([columns]) instead to get only the columns you need\")\n",
    "        return self.get_df()\n",
    "\n",
    "    # Try to keep uam abstracted away\n",
    "    @property\n",
    "    def authenticated(self):\n",
    "        return self.uam.authenticated\n",
    "    \n",
    "    @property\n",
    "    def admin(self):\n",
    "        return self.uam.admin\n",
    "\n",
    "    @property\n",
    "    def user(self):\n",
    "        return self.uam.user\n",
    "    \n",
    "    def log_event(self, event, uid=None):\n",
    "        log_event(event, uid or self.user['uid'], self.log_path, s3_fs=self.s3fs)\n",
    "\n",
    "    # pos_id is for plot_width to work in columns\n",
    "    def plot(self, pp_desc, pos_id='main', width=None, **kwargs):\n",
    "        if width is None: # Find or reuse auto-width\n",
    "            width = self.p_widths[pos_id] if pos_id in self.p_widths else get_plot_width(pos_id)\n",
    "            self.p_widths[pos_id] = width\n",
    "\n",
    "        # If multiple data sources are used, make sure we key it in for caching purposes\n",
    "        pp_desc['data'] = self.data_source\n",
    "        \n",
    "        # Draw plot\n",
    "        st_plot(pp_desc,\n",
    "                width=width, translate=lambda s: self.tf(s,context='data'),\n",
    "                plot_cache=plot_cache() if self.plot_caching else None,\n",
    "                full_df=self.ldf,data_meta=self.meta,**kwargs)\n",
    "        \n",
    "    def filter_ui(self, dims, flt={}, detailed=False, raw=False, force_choice=False, key=''):\n",
    "        return filter_ui(self.ldf, self.meta, uid=f'{key}_{self.page_name}', dims=dims, flt=flt, detailed=detailed, raw=raw, translate=self.tf, force_choice=force_choice)\n",
    "    \n",
    "    def facet_ui(self, dims, two=False, raw=False, force_choice=False, label='Facet', key=''):\n",
    "        return facet_ui(dims, two=two, raw=raw, uid=f'{key}_{self.page_name}', translate=self.tf,force_choice=force_choice,label=label)\n",
    "\n",
    "    def page(self, name, **kwargs):\n",
    "        def decorator(pfunc):\n",
    "\n",
    "            # If we have a whitelist of organizations, and the user is not in it, don't show any pages\n",
    "            # This is the second line of defense as whitelist is also checked in build()\n",
    "            if self.uam.org_whitelist and self.user.get('organization') not in self.uam.org_whitelist:\n",
    "                return\n",
    "\n",
    "            needed_groups = kwargs.get('groups')\n",
    "            if (needed_groups is None or # Page is available to all\n",
    "                self.admin or # Admin sees all\n",
    "                'guest' in needed_groups or # some views might be open to all\n",
    "                len(set(self.user.get('groups',[])) & set(needed_groups)) > 0): # one of the groups is whitelisted\n",
    "                self.pages.append( (name,pfunc,kwargs) )\n",
    "        return decorator\n",
    "\n",
    "    def build(self):\n",
    "\n",
    "        # This is to avoid a bug of the option menu not showing up on reload\n",
    "        # I don't get how this row fixes the issue, but it does\n",
    "        #https://github.com/victoryhb/streamlit-option-menu/issues/68\n",
    "        # This is a quirk of the old login and should be removed with it\n",
    "        if (isinstance(self.uam,StreamlitAuthenticationManager) and \n",
    "            st.session_state.get(\"authentication_status\") and st.session_state[\"logout\"] is None):\n",
    "            st.session_state[\"logout\"] = True \n",
    "            st.rerun()\n",
    "\n",
    "        # If login failed and is required, don't go any further\n",
    "        if not self.public and not self.authenticated: return\n",
    "\n",
    "        # Logged in: add info about thtat + log out option\n",
    "        if self.authenticated:\n",
    "            with st.sidebar:\n",
    "                self.sb_info.info(self.tf('Logged in as **%s**',context='ui') % self.user[\"name\"])\n",
    "                self.uam.logout_button(self.tf('Log out',context='ui'), 'sidebar')\n",
    "\n",
    "\n",
    "        # If we have a whitelist of organizations, and the user is not in it, don't show the page\n",
    "        if self.uam.org_whitelist and self.user.get('organization') not in self.uam.org_whitelist:\n",
    "            st.header(\"You are not authorized to access this dashboard!\")\n",
    "            return\n",
    "\n",
    "        # Add user settings page if logged in\n",
    "        if self.authenticated: self.pages.append( ('Settings',user_settings_page,{'icon': 'sliders'}) )\n",
    "    \n",
    "        # Add admin page for admins\n",
    "        if self.admin:  self.pages.append( ('Administration', admin_page,{'icon': 'terminal'}) )\n",
    "        \n",
    "        # Draw the menu listing pages\n",
    "        pnames = [t[0] for t in self.pages]\n",
    "        with st.sidebar:\n",
    "            t_pnames = [ self.tf(pn,context='ui') for pn in pnames]\n",
    "            if len(t_pnames) == 1: menu_choice = t_pnames[0]\n",
    "            else:\n",
    "                menu_choice = option_menu(\"Pages\",\n",
    "                    t_pnames,\n",
    "                    icons=[t[2].get('icon') for t in self.pages],\n",
    "                    styles={\n",
    "                        \"container\": {\"padding\": \"5!important\"}, #, \"background-color\": \"#fafafa\"},\n",
    "                        #\"icon\": {\"color\": \"red\", \"font-size\": \"15px\"},\n",
    "                        \"nav-link\": {\"font-size\": \"12px\", \"text-align\": \"left\", \"margin\":\"0px\", \"--hover-color\": \"#eee\"},\n",
    "                        \"nav-link-selected\": {\"background-color\": \"#red\"},\n",
    "                        \"menu-title\": {\"display\":\"none\"}\n",
    "                    })\n",
    "            \n",
    "        # Find the page\n",
    "        pname, pfunc, meta = self.pages[t_pnames.index(menu_choice)]\n",
    "        self.page_name = pname\n",
    "        \n",
    "        # Load data\n",
    "        self.data_source = meta.get('data_source',self.data_source)\n",
    "        with st.spinner(self.tf(\"Loading data...\",context='ui')):\n",
    "\n",
    "            update_manifest(self.data_source)\n",
    "\n",
    "            # Download the data if it's not already locally present\n",
    "            # This is done because lazy loading over s3 is very painfully slow as data files are big\n",
    "            if not os.path.exists(self.data_source):\n",
    "                print(f'Downloading {self.filemap[self.data_source]} to {self.data_source}')\n",
    "                self.s3fs.download(self.filemap[self.data_source],self.data_source)\n",
    "\n",
    "            self.ldf, self.meta = read_annotated_data_lazy_cached(self.data_source)\n",
    "            #self.df = self.ldf.collect().to_pandas() # Backwards compatibility\n",
    "\n",
    "        # Render the chosen page\n",
    "        self.subheader(pname,context='ui')\n",
    "\n",
    "        shared = call_kwsafe(self.header_fn,sdb=self) if self.header_fn else {}\n",
    "        pres = call_kwsafe(pfunc, sdb=self, shared=shared)\n",
    "        if pres: shared.update(pres)\n",
    "        if self.footer_fn: call_kwsafe(self.footer_fn, sdb=self, shared=shared)\n",
    "\n",
    "        if self.admin:\n",
    "            with self.sidebar:\n",
    "                st.write(\"Mem: %.1fMb\" % (psutil.Process(os.getpid()).memory_info().rss / 1024 ** 2))\n",
    "                if self.plot_caching:\n",
    "                    pcache = plot_cache()\n",
    "                    st.write(\"Plot cache: %d items (%.1fMb)\" % (len(pcache), get_size(pcache) / 1024 ** 2))\n",
    "                \n",
    "                with st.expander(\"Impersonate (Admin)\"):\n",
    "                    org_list = (self.uam.org_whitelist or []) + ([self.user.get('organization')] if self.user.get('organization') else [])\n",
    "                    org = st.selectbox(\"Organization\",org_list,index=org_list.index(self.user.get('organization')))\n",
    "                    \n",
    "                    group = st.selectbox(\"Group\",self.uam.groups,index=self.uam.groups.index('user'))\n",
    "                    \n",
    "                    langs = list(self.cc_translations.keys()) + ([self.user.get('lang')] if self.user.get('lang') not in self.cc_translations else [])\n",
    "                    language = st.selectbox(\"Language\",langs,index=langs.index(self.user['lang']))\n",
    "                    if st.button(\"Impersonate\"):\n",
    "                        st.success(\"Starting impersonation\")\n",
    "                        if language != self.user['lang']: self.set_translate(language,remember=True)\n",
    "                        self.uam.impersonate({'organization':org,'group':group,'lang':language})\n",
    "                    st.text(\"Browser refresh clears the impersonation\")\n",
    "                    \n",
    "    # Add enter and exit so it can be used as a context\n",
    "    def __enter__(self):\n",
    "        return self\n",
    "    \n",
    "    # Render everything once we exit the with block\n",
    "    def __exit__(self, exc_type, exc_value, exc_tb):\n",
    "        self.build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stauth.Hasher(['kalasaba']).generate() # To generate passwords hashes manually if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "\n",
    "class UserAuthenticationManager:\n",
    "\n",
    "    def __init__(self, groups, info, org_whitelist, logger, languages, translate_func):\n",
    "        self.groups, self.info  = groups,  info\n",
    "        self.org_whitelist = org_whitelist\n",
    "        self.languages = languages\n",
    "        self.log_event = logger\n",
    "        self.tf = translate_func\n",
    "        self.passwordless = False\n",
    "\n",
    "        # Mark that we should log the next login\n",
    "        if 'log_event' not in st.session_state: st.session_state['log_event'] = True\n",
    "\n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def authenticated(self):\n",
    "        pass\n",
    "\n",
    "    @property\n",
    "    def admin(self):\n",
    "        return self.authenticated and (self.user.get('group') == 'admin')\n",
    "\n",
    "    def require_admin(self):\n",
    "        if not self.admin: raise Exception(\"This action requires administrator privileges\")\n",
    "\n",
    "    @abstractmethod\n",
    "    def uam_user(self):\n",
    "        pass\n",
    "\n",
    "    @property\n",
    "    def user(self):\n",
    "        base = self.uam_user().copy()\n",
    "        if st.session_state.get('impersonate_user'): base.update(st.session_state['impersonate_user'])\n",
    "        return base\n",
    "\n",
    "        \n",
    "    @abstractmethod\n",
    "    def login_screen(self):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def logout_button(self,text,location='sidebar'):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def add_user(self, user_data):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def change_user(self, uid, user_data):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def delete_user(self, uid):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def list_users(self):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def update_user(self, uid):\n",
    "        pass\n",
    "\n",
    "    def impersonate(self,user_data):\n",
    "        self.require_admin()\n",
    "        st.session_state['impersonate_user'] = user_data\n",
    "        st.rerun()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "\n",
    "# TODO\n",
    "# - centralize the db connection, getting url and token from env\n",
    "# - move other conf (cookie token) to streamlit env variables\n",
    "# - create a database with username as id and migrate the auth_conf on the web\n",
    "\n",
    "@st.cache_resource\n",
    "def sqlite_client(url, token):\n",
    "    print(f\"User database from {url}\")\n",
    "    return libsql_client.create_client_sync(url=url, auth_token=token)\n",
    "\n",
    "class StreamlitAuthenticationManager(UserAuthenticationManager):\n",
    "    \n",
    "    def __init__(self,auth_conf_file,groups,org_whitelist,s3_fs,info,logger,languages,translate_func):\n",
    "        super().__init__(groups, info, org_whitelist, logger, languages, translate_func)\n",
    "        self.s3fs = s3_fs\n",
    "        self.stuser = {}\n",
    "        self.client = None\n",
    "        self.conf_file = auth_conf_file\n",
    "        self.load_conf()\n",
    "        self.passwordless = False\n",
    "        config = self.conf\n",
    "        self.auth = stauth.Authenticate(\n",
    "            config['credentials'],\n",
    "            config['cookie']['name'],\n",
    "            config['cookie']['key'],\n",
    "            config['cookie']['expiry_days'],\n",
    "            [] # config['preauthorized'] - not using preauthorization\n",
    "        )\n",
    "\n",
    "\n",
    "    @property\n",
    "    def authenticated(self):\n",
    "        return (st.session_state.get(\"authentication_status\") and self.stuser)\n",
    "\n",
    "    # This is abstracted into .user property with impersonation built-in\n",
    "    def uam_user(self):\n",
    "        if self.stuser and self.stuser.get('username'):\n",
    "            return {\n",
    "                'uid': self.stuser['username'],\n",
    "                'name': self.stuser['name'],\n",
    "                'username': self.stuser['username'],\n",
    "                'group': self.stuser['group'],\n",
    "                'organization': self.stuser['organization'],\n",
    "                'lang': self.stuser['lang']\n",
    "            }\n",
    "        else:\n",
    "            return {}\n",
    "\n",
    "    def logout_button(self, text, location='sidebar'):\n",
    "        self.auth.logout(text, location)\n",
    "    \n",
    "    def load_conf(self,cached=True):\n",
    "        if cached: self.conf = load_json_cached(self.conf_file, _s3_fs = self.s3fs)\n",
    "        else: self.conf = load_json(self.conf_file, _s3_fs = self.s3fs)\n",
    "\n",
    "        if 'libsql' in self.conf:\n",
    "            url, token = self.conf['libsql']['url'], self.conf['libsql']['token']\n",
    "            self.client = sqlite_client(url=url, token=token)\n",
    "            ures = self.client.execute(\"SELECT * FROM users\")\n",
    "            self.conf['credentials']['usernames'] = { u['username']:dict(zip(ures.columns,u)) for u in ures.rows }\n",
    "        \n",
    "        if self.org_whitelist is not None:\n",
    "            for ud in self.conf['credentials']['usernames'].values():\n",
    "                ud['whitelisted'] = ud.get('organization') in self.org_whitelist or ud.get('group') == 'admin'\n",
    "\n",
    "            if not self.admin:\n",
    "                self.conf['credentials']['usernames'] = {\n",
    "                    un:ud for un,ud in self.conf['credentials']['usernames'].items()\n",
    "                    if ud.get('whitelisted')\n",
    "                }\n",
    "\n",
    "        self.users = self.conf['credentials']['usernames']\n",
    "    \n",
    "    def login_screen(self):\n",
    "\n",
    "        tf = self.tf\n",
    "        _, _, username = self.auth.login('sidebar', fields={'Form name':tf('Login page'), 'Username':tf('Username'), 'Password':tf('Password'), 'Log in':tf('Log in')})\n",
    "            \n",
    "        if st.session_state[\"authentication_status\"] is False:\n",
    "            st.error(tf('Username/password is incorrect'))\n",
    "            self.log_event('login-fail', username=username)\n",
    "        if st.session_state[\"authentication_status\"] is None:\n",
    "            st.warning(tf('Please enter your username and password'))\n",
    "            st.session_state['log_event'] = True \n",
    "        elif st.session_state[\"authentication_status\"]:\n",
    "            self.stuser = {'name': st.session_state['name'], \n",
    "                        'username': username,\n",
    "                        **self.users[username] }\n",
    "            \n",
    "            #check if signing in has been logged - if not, log it and flip the flag\n",
    "            if st.session_state['log_event']:\n",
    "                self.log_event('login-success')\n",
    "                st.session_state['log_event'] = False\n",
    "        \n",
    "    def update_conf(self, username):\n",
    "\n",
    "        # Read full conf file (can have more users, as load_conf filters them)\n",
    "        full_conf = load_json(self.conf_file, _s3_fs = self.s3fs)\n",
    "\n",
    "        full_u = full_conf['credentials']['usernames']\n",
    "        cur_u = self.users\n",
    "\n",
    "        # Update the user's entry\n",
    "        if username not in cur_u and username in full_u:\n",
    "            del full_u[username] # Delete\n",
    "        else: full_u[username] = cur_u[username] # Update\n",
    "\n",
    "        with open_fn(self.conf_file,'w',s3_fs=self.s3fs) as jf:\n",
    "            json.dump(full_conf,jf)\n",
    "        time.sleep(3) # Give some time for messages to display etc\n",
    "        st.rerun() # Force a rerun to reload the new file\n",
    "\n",
    "    def update_user(self,username):\n",
    "        if 'libsql' in self.conf:\n",
    "            user_data = self.users[username]\n",
    "            self.client.execute('UPDATE users SET name = ?, email = ?, organization = ?, \"group\" = ?, password = ?, lang = ? WHERE username = ?',\n",
    "                         [user_data['name'], user_data['email'], user_data['organization'], \n",
    "                          user_data['group'], user_data['password'], user_data['lang'], username])\n",
    "        else: self.update_conf(username)\n",
    "            \n",
    "    def add_user(self, user_data):\n",
    "        self.require_admin()\n",
    "        username = user_data['username']\n",
    "        if username not in self.users:\n",
    "            password = user_data.get('password')\n",
    "            user_data['password'] = stauth.Hasher([password]).generate()[0]\n",
    "            self.users[username] = user_data\n",
    "            self.info.success(f'User {username} successfully added.')\n",
    "            self.log_event(f'add-user: {username}')\n",
    "            \n",
    "            if 'libsql' in self.conf:\n",
    "                self.client.execute('INSERT INTO users (username, name, email, organization, \"group\", password) VALUES (?, ?, ?, ?, ?, ?)',\n",
    "                               [username, user_data['name'], user_data['email'], user_data['organization'], \n",
    "                                user_data['group'], user_data['password']])\n",
    "            else: self.update_conf(username)\n",
    "            return True\n",
    "        else:\n",
    "            self.info.error(f'User **{username}** already exists.')\n",
    "            return False\n",
    "        \n",
    "    def change_user(self, username, user_data):\n",
    "        # Change username\n",
    "        if 'username' in user_data and username != user_data['username']:\n",
    "            self.users[user_data['username']] = self.users[username]\n",
    "            del self.users[username]\n",
    "            username = user_data['username']\n",
    "            del user_data['username']\n",
    "        \n",
    "        # Handle password change\n",
    "        if user_data.get('password'):\n",
    "            user_data['password'] = stauth.Hasher([user_data['password']]).generate()[0]\n",
    "        else: user_data['password'] = self.users[username]['password']\n",
    "        \n",
    "        # Update everything else\n",
    "        self.users[username].update(user_data)\n",
    "        self.log_event(f'change-user: {username}')\n",
    "        self.info.success(f'User **{username}** changed.')\n",
    "        self.update_user(username)\n",
    "        \n",
    "    def delete_user(self, username): \n",
    "        self.require_admin()\n",
    "        del self.users[username]\n",
    "        self.info.warning(f'User **{username}** deleted.')\n",
    "        self.log_event(f'delete-user: {username}')\n",
    "\n",
    "        if 'libsql' in self.conf:\n",
    "            self.client.execute('DELETE FROM users WHERE username = ?', [username])\n",
    "        else:\n",
    "            self.update_conf(username)\n",
    "\n",
    "    def list_users(self):\n",
    "        self.require_admin()\n",
    "        self.load_conf(cached=False) # so all admin updates would immediately be visible\n",
    "        return { k: censor_dict({'uid': k, **v},['password']) for k,v in self.users.items() }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "\n",
    "@st.cache_resource\n",
    "def frontegg_client():\n",
    "    from frontegg.common.clients import HttpClient\n",
    "    base_url = \"https://api.frontegg.com/audits\"\n",
    "    auth = st.secrets['auth']\n",
    "    return HttpClient(client_id=auth['client_id'], api_key=auth['client_secret'], base_url=base_url)\n",
    "\n",
    "class FronteggAuthenticationManager(UserAuthenticationManager):\n",
    "\n",
    "    def __init__(self, groups, info, org_whitelist, logger, languages, translate_func):\n",
    "        super().__init__(groups, info, org_whitelist, logger, languages, translate_func)\n",
    "        self.client = frontegg_client()\n",
    "        self.passwordless = True\n",
    "\n",
    "    @property\n",
    "    def authenticated(self):\n",
    "        return st.user['is_logged_in']\n",
    "\n",
    "    def reform_user(self, user):\n",
    "        meta = user.get('metadata') or {}\n",
    "        if isinstance(meta,str): meta = json.loads(meta)\n",
    "        return {\n",
    "            'uid': user['email'],\n",
    "            'name': user.get('name',''),\n",
    "            'email': user['email'],\n",
    "            #'username': st.user['cognito:username'],\n",
    "            'group': meta.get('group','guest'),\n",
    "            'organization': meta.get('organization'),\n",
    "            'lang': meta.get('lang'),\n",
    "        }\n",
    "\n",
    "    # This is abstracted into .user property with impersonation built-in\n",
    "    def uam_user(self):\n",
    "        # As st.user is not updated unless you log out, and is not writable\n",
    "        # We need the hacky workaround to allow changing user info (like lang) during session\n",
    "        # Normally, one would just do an oauth refresh on user change, but streamlit does not support that (yet?)\n",
    "        if not st.user['is_logged_in']:\n",
    "            return {}\n",
    "        elif 'OAUser' not in st.session_state:\n",
    "            st.session_state['OAUser'] = self.reform_user(st.user)\n",
    "        return st.session_state.get('OAUser')\n",
    "\n",
    "\n",
    "    # Use the silent login profile to just refresh the user info if prompt config is present\n",
    "    def refresh_user(self):\n",
    "        # If prompr config present, assume default conf is silent login\n",
    "        # In that case, logout + silent login can be used to refresh the user info\n",
    "        if 'prompt' in st.secrets['auth']:\n",
    "            st.logout()\n",
    "        else: print('User refresh needs [auth.prompt] segment in secrets.toml')\n",
    "\n",
    "    def login_screen(self):\n",
    "        if not self.authenticated:\n",
    "            st.login()\n",
    "            st.session_state['OA_fresh'] = True # just logged in, so no need to refresh\n",
    "            if st.user['is_logged_in'] and not st.session_state.get('OAUser'): \n",
    "                st.session_state['OAUser'] = self.reform_user(st.user)\n",
    "            elif not st.user['is_logged_in'] and 'OAUser' in st.session_state: \n",
    "                del st.session_state['OAUser']\n",
    "        elif not st.session_state.get('OA_fresh') and time.time()-st.user['iat']>60:\n",
    "            # IF authenticated, but token not refreshed this session and is at least 60 sec old\n",
    "            # This is to ensure that settings changes are also visible if logging in on another device\n",
    "            # Also good for keeping users logged in for a while as it refreshes the access token\n",
    "            print('Refreshing user info')\n",
    "            self.refresh_user()\n",
    "        else: st.session_state['OA_fresh'] = True\n",
    "\n",
    "        # Record the login event to the log file    \n",
    "        if self.authenticated and 'login_recorded' not in st.session_state:\n",
    "            self.log_event('login-success')\n",
    "            st.session_state['login_recorded'] = True # Only log once per session, even if user logs in multiple times  \n",
    "\n",
    "    def logout_button(self,text,location='sidebar'):\n",
    "        where = st.sidebar if location == 'sidebar' else st\n",
    "        if 'prompt' in st.secrets['auth'] and st.button(text):\n",
    "            st.login('prompt')\n",
    "        #st.write(self.reform_user(st.user)) # Debug: show sdb.user\n",
    "\n",
    "    def add_user(self, user_data):\n",
    "        self.require_admin()\n",
    "        res = self.client.post(url='identity/resources/users/v1/', data={\n",
    "            'email':user_data['email'].strip(),\n",
    "            'verified':True,\n",
    "            'name':user_data['name'].strip(),\n",
    "            'metadata':json.dumps({\n",
    "                'group':user_data['group'],\n",
    "                'organization':user_data['organization'],\n",
    "                'lang':user_data['lang']\n",
    "            }),\n",
    "            'roleIds': []\n",
    "        },headers={'frontegg-tenant-id':st.user['tenantId']}).json() # Add to same tenant as admin\n",
    "        \n",
    "        if res.get('errors'): raise Exception(str(res['errors']))\n",
    "        self.info.info(f'User **{res['email']}** added.')\n",
    "        self.log_event(f'add-user: {res['email']}')\n",
    "\n",
    "    def change_user(self, uid, user_data):\n",
    "        if uid != self.user['uid']: self.require_admin()\n",
    "        uinfo = self.client.get(f'identity/resources/users/v1/email?email={uid}').json()\n",
    "        if 'email' in user_data and user_data['email'] != uinfo['email']:\n",
    "            eres = self.client.put(url=f'identity/resources/users/v1/{uinfo['id']}/email',data={'email':user_data['email'].strip()})\n",
    "            if eres.get('errors'): raise Exception(str(eres['errors']))\n",
    "\n",
    "        # Change everything else:\n",
    "        res = self.client.put(url=f'identity/resources/users/v1/{uinfo['id']}',data={\n",
    "            'name':user_data['name'],\n",
    "            'metadata':json.dumps({\n",
    "                'group':user_data['group'],\n",
    "                'organization':user_data['organization'],\n",
    "                'lang':user_data['lang']\n",
    "            })\n",
    "        }).json()\n",
    "\n",
    "        if res.get('errors'): raise Exception(str(res['errors']))\n",
    "        self.info.info(f'User **{uid}** updated.')\n",
    "        self.log_event(f'change-user: {uid}')\n",
    "\n",
    "        if uid == self.user['uid']:\n",
    "            self.refresh_user()\n",
    "            #st.session_state['OAUser'] = self.reform_user(res)\n",
    "        \n",
    "    def delete_user(self, uid):\n",
    "        self.require_admin()\n",
    "        uinfo = self.client.get(f'identity/resources/users/v1/email?email={uid}').json()\n",
    "        res = self.client.delete(f'identity/resources/users/v1/{uinfo['id']}')\n",
    "\n",
    "        #if res.get('error'): raise Exception(res['error'])\n",
    "        self.info.info(f'User **{uid}** deleted.')\n",
    "        self.log_event(f'delete-user: {uid}')\n",
    "\n",
    "\n",
    "    def list_users(self):\n",
    "        self.require_admin()\n",
    "        # TODO: this endpoint is paginated, so we may need to cycle over all pages here\n",
    "        res = self.client.get('identity/resources/users/v1/?_limit=200',headers={'frontegg-tenant-id':'7779b9fb-f279-4cd3-8f61-e751a0d06145'})\n",
    "        return { i['email']: censor_dict(self.reform_user(i),[]) for i in res.json()['items'] }\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Admin pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti \n",
    "\n",
    "# Password reset\n",
    "def user_settings_page(sdb):\n",
    "    if not sdb.user: return\n",
    "\n",
    "    cur_lang = st.session_state.get('lang')\n",
    "    opts = [cur_lang] + [l for l in sdb.cc_translations.keys() if l != cur_lang]\n",
    "    lang = st.selectbox(sdb.tf(\"Language:\",context='ui'), opts)\n",
    "\n",
    "    if sdb.button('Save'):\n",
    "        if lang != cur_lang:\n",
    "            sdb.set_translate(lang,remember=True)\n",
    "\n",
    "        if lang!=sdb.user['lang']:\n",
    "            user = sdb.user.copy()\n",
    "            user['lang'] = lang\n",
    "            sdb.uam.change_user(sdb.user['uid'],user)\n",
    "        st.rerun()\n",
    "\n",
    "    if isinstance(sdb.uam,StreamlitAuthenticationManager):\n",
    "        try:\n",
    "            tf = lambda s: sdb.tf(s,context='ui')\n",
    "            if sdb.uam.auth.reset_password(st.session_state[\"username\"], \n",
    "                                        fields={'Form name':tf('Reset password'), 'Current password':tf('Current password'), \n",
    "                                                'New password':tf('New password'), 'Repeat password': tf('Repeat password'), \n",
    "                                                'Reset':tf('Reset')}):\n",
    "                sdb.uam.update_user(st.session_state[\"username\"])\n",
    "                st.success(tf('Password modified successfully'))\n",
    "        except Exception as e:\n",
    "            st.error(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "\n",
    "# Helper function to highlight log rows\n",
    "def highlight_cells(val):\n",
    "    if 'fail' in val:\n",
    "        color = 'red'\n",
    "    #elif 'add' in val:\n",
    "    elif any(s in val for s in ['delete', 'add', 'change']):\n",
    "        color = 'blue'\n",
    "    elif 'success' in val:\n",
    "        color='green'\n",
    "    else:\n",
    "        color = ''\n",
    "    return 'color: {}'.format(color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "\n",
    "# Admin page to manage users\n",
    "\n",
    "def admin_page(sdb):\n",
    "    sdb.uam.require_admin()\n",
    "    \n",
    "    menu_choice = option_menu(None,[ 'Log management', 'List users', 'Add user', 'Change user', 'Delete user' ], \n",
    "                              icons=['card-list','people-fill','person-fill-add','person-lines-fill','person-fill-dash'], orientation='horizontal')\n",
    "    st.write(\" \")\n",
    "\n",
    "    all_users = sdb.uam.list_users()\n",
    "\n",
    "    if menu_choice=='Log management':\n",
    "        log_data=pd.read_csv(alias_file(sdb.log_path,sdb.filemap),names=['timestamp','event','uid'])\n",
    "        st.dataframe(log_data.sort_index(ascending=False\n",
    "            ).style.map(highlight_cells, subset=['event']), width=1200) #use_container_width=True\n",
    "        \n",
    "    elif menu_choice=='List users':\n",
    "        # Read log to get last login:\n",
    "        log_data = pd.read_csv(alias_file(sdb.log_path,sdb.filemap),names=['timestamp','event','uid'])\n",
    "        log_data = log_data[log_data['event']=='login-success']\n",
    "        log_data['timestamp'] = pd.to_datetime(log_data['timestamp'], utc=True, format='%d-%m-%Y, %H:%M:%S')\n",
    "        \n",
    "        # Add last login to users\n",
    "        users = list(all_users.values())\n",
    "        for u in users:\n",
    "            last_login = log_data[log_data['uid'] == u['uid']].timestamp.max()\n",
    "            u['last_login'] = last_login if pd.notnull(last_login) else None\n",
    "\n",
    "        if sdb.uam.org_whitelist is not None:\n",
    "            for ud in users:\n",
    "                ud['whitelisted'] = ud.get('organization') in sdb.uam.org_whitelist or ud.get('group') == 'admin'\n",
    "\n",
    "\n",
    "        users = pd.DataFrame(users)\n",
    "        users['last_login'] = pd.to_datetime(users['last_login'])\n",
    "        users = users.sort_values(by=['whitelisted','last_login'], ascending=False)\n",
    "            \n",
    "        # Display the data\n",
    "        st.dataframe(users, use_container_width=True, column_config={\n",
    "            \"last_login\": st.column_config.DatetimeColumn(\n",
    "                \"last_login\", format=\"D MMM YYYY, HH:mm \" )\n",
    "        })\n",
    "\n",
    "    elif menu_choice=='Add user':\n",
    "        with st.form(\"add_user_form\"):\n",
    "            st.subheader(\"Add user:\")\n",
    "            st.markdown(\"\"\"---\"\"\")\n",
    "            col1,col2 = st.columns((1,2))\n",
    "            user_data = {}\n",
    "            with col1:\n",
    "                user_data['group'] = st.radio(\"Group:\", sdb.uam.groups)\n",
    "            with col2:\n",
    "                if not sdb.uam.passwordless:\n",
    "                    username = st.text_input(\"Username:\")\n",
    "                    password = st.text_input(\"Password:\", type='password')\n",
    "\n",
    "                user_data['name'] = st.text_input(\"Name:\")\n",
    "                st.markdown(\"\"\"---\"\"\")\n",
    "                user_data['email'] = st.text_input(\"E-mail:\")\n",
    "                user_data['organization'] = st.text_input(\"Organization:\")\n",
    "                user_data['lang'] = st.selectbox(\"Language:\", list(sdb.cc_translations.keys())+[None], index=0)\n",
    "            st.markdown(\"\"\"---\"\"\")\n",
    "            submitted = st.form_submit_button(\"Submit\")\n",
    "            if submitted:\n",
    "                if not sdb.uam.passwordless:\n",
    "                    if username in all_users:\n",
    "                        sdb.info.error(f'User **{username}** already exists.')\n",
    "                    elif not '' in [username, password, user_data['email']]:\n",
    "                        user_data['username'] = username\n",
    "                        user_data['password'] = password\n",
    "                        sdb.uam.add_user(user_data)\n",
    "                    else:\n",
    "                        sdb.info.error('Must specify username, password and email.')\n",
    "                else:\n",
    "                    if user_data['email'] in all_users:\n",
    "                        sdb.info.error(f'User **{user_data['email']}** already exists.')\n",
    "                    elif '' in [user_data['email']]:\n",
    "                        sdb.info.error('Must specify email.')\n",
    "                    else:\n",
    "                        sdb.uam.add_user(user_data)\n",
    "\n",
    "    elif menu_choice=='Change user':\n",
    "        uid = st.selectbox('Edit user', list(all_users.keys()))\n",
    "        \n",
    "        user_data = all_users[uid].copy()\n",
    "        #st.write(user_data)\n",
    "        group_index = sdb.uam.groups.index(user_data.get('group','guest'))\n",
    "\n",
    "        with st.form(\"edit_user_form\"):\n",
    "            st.subheader(\"Edit user data:\")\n",
    "            st.markdown(\"\"\"---\"\"\")\n",
    "            col1,col2 = st.columns((1,2))\n",
    "            with col1:\n",
    "                if not sdb.uam.passwordless:\n",
    "                    user_data['username'] = st.text_input(\"Username:\", value=user_data['username'], disabled=True)\n",
    "                user_data['group'] = st.radio(\"Group:\", sdb.uam.groups, index=group_index) #, disabled=True)\n",
    "            with col2:\n",
    "                #new_user = st.text_input(\"Kasutaja:\", value=username, disabled=True)\n",
    "                user_data['name'] = st.text_input(\"Name:\", value=user_data['name'])\n",
    "                if not sdb.uam.passwordless:\n",
    "                    user_data['password'] = st.text_input(\"Password:\", type='password')\n",
    "                st.markdown(\"\"\"---\"\"\")\n",
    "                user_data['email'] = st.text_input(\"E-mail:\", value=user_data['email'])\n",
    "                user_data['organization'] = st.text_input(\"Organization:\", value=user_data.get('organization',''))\n",
    "                cur_lang = user_data.get('lang',None)\n",
    "                l_opts = [cur_lang] + [l for l in list(sdb.cc_translations.keys())+[None] if l != cur_lang]\n",
    "                user_data['lang'] = st.selectbox(\"Language:\", l_opts)\n",
    "                # NB! it is known changing language here for current user does not lead to a change. \n",
    "                # It's not worth the extra code overhead to make it work. \n",
    "                \n",
    "            st.markdown(\"\"\"---\"\"\")\n",
    "            submitted = st.form_submit_button(\"Submit\")\n",
    "            if submitted:\n",
    "                sdb.uam.change_user(uid,user_data)\n",
    "                \n",
    "    elif menu_choice=='Delete user':\n",
    "        with st.form(\"delete_user_form\"):\n",
    "            st.subheader('Delete user:')\n",
    "            uid = st.selectbox('Select username:', list(all_users.keys()))\n",
    "            check = st.checkbox('Deletion is FINAL and cannot be undone!')\n",
    "            st.markdown(\"\"\"___\"\"\")\n",
    "            submitted = st.form_submit_button(\"Delete\")\n",
    "            if submitted:\n",
    "                if not check:\n",
    "                    sdb.warning(f'Tick the checkbox in order to delete user **{uid}**.')\n",
    "                elif uid == sdb.uam.user['uid']:\n",
    "                    sdb.error('Cannot delete the current user.')\n",
    "                else:\n",
    "                    sdb.uam.delete_user(uid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Snippets copied over from dashboard.py to be re-purposed here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other shared parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "# This is a horrible workaround to get faceting to work with altair geoplots that do not play well with streamlit\n",
    "# See https://github.com/altair-viz/altair/issues/2369 -> https://github.com/vega/vega-lite/issues/3729\n",
    "\n",
    "# Draw a matrix of plots using separate plots and st columns\n",
    "def draw_plot_matrix(pmat):\n",
    "    if not pmat: return # Do nothing if get None passed to it\n",
    "    if not isinstance(pmat,list): pmat, ucw = [[pmat]], False\n",
    "    else: ucw = True # If we are drawing more than one plot, we want to use the container width\n",
    "    cols = st.columns(len(pmat[0])) if len(pmat[0])>1 else [st]\n",
    "    for j,c in enumerate(cols):\n",
    "        for i, row in enumerate(pmat):\n",
    "            if j>=len(pmat[i]): continue\n",
    "            #print(pmat[i][j].to_json()) # to debug json\n",
    "            c.altair_chart(pmat[i][j],use_container_width=ucw)#,theme=None)\n",
    "\n",
    "# Draw the plot described by pp_desc \n",
    "def st_plot(pp_desc,**kwargs):\n",
    "    plots = e2e_plot(pp_desc, **kwargs)\n",
    "    draw_plot_matrix(plots)\n",
    "\n",
    "# Create a global plot cache\n",
    "@st.cache_resource(show_spinner=False,ttl=None)\n",
    "def plot_cache():\n",
    "    return dict_cache(size=100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "# Streamlit session state safety - check and clear session state if it has an unfit value\n",
    "def stss_safety(key, opts):\n",
    "    if key in st.session_state and st.session_state[key] not in opts: del st.session_state[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def facet_ui(dims, two=False, uid='base',raw=False, translate=None, force_choice=False, label='Facet'):\n",
    "    # Set up translation\n",
    "    tfc = translate if translate else (lambda s,**kwargs: s)\n",
    "    tf = lambda s: tfc(s,context='data')\n",
    "    \n",
    "    tdims = [ tf(d) for d in dims ]\n",
    "    r_map = dict(zip(tdims,dims))\n",
    "    \n",
    "    none = tf('None')\n",
    "    stc = st.sidebar if not raw else st\n",
    "\n",
    "    stss_safety(f'facet1_{uid}',tdims)\n",
    "    facet_dim = stc.selectbox(tfc(label+':',context='ui'), tdims if force_choice else [none] + tdims, key=f'facet1_{uid}')\n",
    "    fcols = [facet_dim] if facet_dim != none else []\n",
    "    if two and facet_dim != none:\n",
    "        stss_safety(f'facet2_{uid}',tdims)\n",
    "        second_dim = stc.selectbox(tfc(label+' 2:',context='ui'), tdims if force_choice else [none] + tdims, key=f'facet2_{uid}')\n",
    "        if second_dim not in [none,facet_dim]:  fcols = [facet_dim, second_dim]\n",
    "        \n",
    "    return [ r_map[d] for d in fcols ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "\n",
    "# Function that creates reset functions for multiselects in filter\n",
    "def ms_reset(cn, all_vals,uid):\n",
    "    def reset_ms():\n",
    "        st.session_state[f\"filter_{uid}_{cn}_multiselect\"] = all_vals\n",
    "    return reset_ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "\n",
    "@st.cache_data(show_spinner=False)\n",
    "def get_filter_limits(_ldf,dims,dmeta,uid):\n",
    "    ldf = _ldf\n",
    "\n",
    "    if not isinstance(ldf,pl.LazyFrame): ldf = pl.DataFrame(ldf).lazy()\n",
    "\n",
    "    schema = ldf.collect_schema()\n",
    "\n",
    "    if dims is None: dims = schema.names()\n",
    "    else: dims = [ c for c in dims if c in schema.names() ]\n",
    "\n",
    "    c_meta = extract_column_meta(dmeta)\n",
    "\n",
    "    limits = {}\n",
    "    for d in dims:\n",
    "        if c_meta[d].get('continuous') and schema[d].is_numeric():\n",
    "            if c_meta[d].get('val_range'): limits[d] = { 'min': c_meta[d]['val_range'][0], 'max': c_meta[d]['val_range'][1] }\n",
    "            else: limits[d] = ldf.select([pl.min(d).alias('min'),pl.max(d).alias('max')]).collect().to_dicts()[0]\n",
    "            limits[d]['continuous'] = True\n",
    "        elif c_meta[d].get('categories'):\n",
    "            if c_meta[d].get('categories') == 'infer':\n",
    "                if schema[d].is_numeric():\n",
    "                    warn(f'Column {d} is numeric but marked as categorical. Skipping in filter as inferring categories is not possible.')\n",
    "                    continue\n",
    "                else:\n",
    "                    limits[d] = { 'categories': ldf.select(pl.all()).unique(d).collect().to_series().sort().to_list() }\n",
    "            else:\n",
    "                limits[d] = { 'categories': c_meta[d]['categories'] } \n",
    "                \n",
    "            limits[d]['ordered'] = c_meta[d].get('ordered',False)\n",
    "        else:\n",
    "            warn(f\"Skipping {d}: {c_meta[d]} in filter\")\n",
    "    return limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "# User interface that outputs a filter for the pp_desc\n",
    "def filter_ui(data, dmeta=None, dims=None, flt={}, uid='base', detailed=False, raw=False, translate=None, force_choice=False, grouped=False):\n",
    "    \n",
    "    tfc = translate if translate else (lambda s,**kwargs: s)\n",
    "    tf = lambda s: tfc(s,context='data')\n",
    "\n",
    "    limits = get_filter_limits(data,dims,dmeta,uid)\n",
    "    dims = list(limits.keys())\n",
    "    \n",
    "    if dmeta is not None:\n",
    "        gcols = group_columns_dict(dmeta)\n",
    "        dims = list_aliases(dims, gcols) # Replace aliases like 'demographics'\n",
    "        c_meta = extract_column_meta(dmeta) # mainly for groups defined in meta\n",
    "    else: c_meta = defaultdict(lambda: {})\n",
    "    \n",
    "    if not force_choice: f_info = st.sidebar.container()\n",
    "    \n",
    "    gstc = st.sidebar.expander(tfc('Filters',context='ui')) if not raw else st\n",
    "    stss = st.session_state\n",
    "    \n",
    "\n",
    "    if grouped: \n",
    "        gdims = { gn: [d for d in gdims if d in dims] for gn,gdims in gcols.items() }\n",
    "        gdims = [ (gstc.expander(gn,expanded=(gn=='main')), gd) for gn, gd in gdims.items() if len(gd)>0 ]\n",
    "    else:\n",
    "        gdims = [ (gstc, dims) ]\n",
    "\n",
    "    # Different selector for different category types\n",
    "    # Also - make sure filter is clean and only applies when it is changed from the default 'all' value\n",
    "    # This has considerable speed and efficiency implications\n",
    "    filters = deepcopy(flt)\n",
    "    for stc, dims in gdims:\n",
    "        for cn in dims:\n",
    "            \n",
    "            # Shared prep for all cateogoricals\n",
    "            if limits[cn].get('categories'):\n",
    "                cats = limits[cn]['categories']\n",
    "\n",
    "                if cn in flt: # Already a filter set\n",
    "                    cflt = flt[cn]\n",
    "                    if not isinstance(cflt,list): cflt = [cflt] # Single value\n",
    "                    if cflt[0] is None:\n",
    "                        miv, mav = cflt[1:]\n",
    "                        if not {miv,mav} <= set(cats):\n",
    "                            raise ValueError(f\"Invalid filter for {cn}: {cflt}\")\n",
    "                        cflt = cats[cats.index(miv):cats.index(mav)+1]\n",
    "                    cats = cflt # Set the list of options to the current filter\n",
    "\n",
    "                if len(cats)==1: continue\n",
    "                \n",
    "                # Do some prep for translations\n",
    "                r_map = dict(zip([tf(c) for c in cats],cats))\n",
    "                all_vals = list(r_map.keys()) # translated categories\n",
    "                grp_names = c_meta[cn].get('groups',{}).keys()\n",
    "                r_map.update(dict(zip([tf(c) for c in grp_names],grp_names)))\n",
    "            \n",
    "            # Multiselect\n",
    "            if detailed and limits[cn].get('categories'):\n",
    "                key = f\"filter_{uid}_{cn}_multiselect\"\n",
    "                if key in stss and not set(stss[key]) <= set(all_vals): del stss[key]  \n",
    "                filters[cn] = stc.multiselect(tf(cn), all_vals, all_vals, key=key)\n",
    "                if set(filters[cn]) == set(all_vals): del filters[cn]\n",
    "                else: \n",
    "                    stc.button(tf(\"Reset\"),key=f\"filter_{uid}_{cn}_ms_reset\",on_click=ms_reset(cn,all_vals,uid))\n",
    "                    filters[cn] = [ r_map[c] for c in filters[cn] ]\n",
    "\n",
    "            # Unordered categorical - selectbox\n",
    "            elif limits[cn].get('categories') and not limits[cn].get('ordered'): \n",
    "                choices = [gt for gt,g in r_map.items() if g in grp_names] + all_vals\n",
    "                if not force_choice: choices = [tf('All')] + choices\n",
    "                stss_safety(f'filter_{cn}_sel',choices)\n",
    "                key = f'filter_{uid}_{cn}_sel'\n",
    "                if key in stss and stss[key] not in all_vals: del stss[key]\n",
    "                filters[cn] = stc.selectbox(tf(cn),choices,key=key)\n",
    "                if filters[cn] == tf('All'): del filters[cn]\n",
    "                else: filters[cn] = r_map[filters[cn]]\n",
    "\n",
    "            # Ordered categorical - slider\n",
    "            # Use [None,<start>,<end>] for ranges, both categorical and continuous to distinguish them from list of values\n",
    "            elif limits[cn].get('categories') and limits[cn].get('ordered'): # Ordered categorical - slider\n",
    "                key = f'filter_{uid}_{cn}_ocat'\n",
    "                if key in stss and not set(stss[key]) <= set(all_vals): del stss[key] \n",
    "                f_res = stc.select_slider(tf(cn),all_vals,value=(all_vals[0],all_vals[-1]),key=key)\n",
    "                if f_res != (all_vals[0],all_vals[-1]):\n",
    "                    miv, mav = r_map[f_res[0]], r_map[f_res[1]]\n",
    "                    if cn in flt: filters[cn] = cats[cats.index(miv):cats.index(mav)+1] # As cats itself might already be a subset\n",
    "                    else: filters[cn] = [None]+[miv,mav] # Just use the range syntax for better legibility\n",
    "\n",
    "            # Numeric values - slider\n",
    "            elif limits[cn].get('continuous'): # Continuous\n",
    "                mima = limits[cn]['min'], limits[cn]['max']\n",
    "                if mima[0]==mima[1]: continue\n",
    "                f_res = stc.slider(tf(cn),*mima,value=mima,key=f'filter_{uid}_{cn}_cont')\n",
    "                if f_res[0]>mima[0] or f_res[1]<mima[1]: \n",
    "                    filters[cn] = ( [None] + \n",
    "                                    [ f_res[0] if f_res[0]>mima[0] else None] + \n",
    "                                    [ f_res[1] if f_res[1]<mima[1] else None ] )\n",
    "            \n",
    "    if filters and not force_choice: f_info.warning(' ' + tfc('Filters active',context='ui') + ' ')\n",
    "            \n",
    "    return filters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translation tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "# Use dict here as dicts are ordered as of Python 3.7 and preserving order groups things together better\n",
    "\n",
    "def translate_with_dict(d):\n",
    "    return (lambda s: d[s] if isinstance(s,str) and s in d and d[s] is not None else s)\n",
    "\n",
    "def log_missing_translations(tf, nonchanged_dict):\n",
    "    def ntf(s):\n",
    "        ns = tf(s)\n",
    "        if ns==s: nonchanged_dict[s]=None\n",
    "        return ns\n",
    "    return ntf\n",
    "\n",
    "def clean_missing_translations(nonchanged_dict, tdict={}):\n",
    "    # Filter out numbers that come in from data sometimes\n",
    "    return { s:v for s,v in nonchanged_dict.items() if s not in tdict and isinstance(s,str) and not re.fullmatch(r'[.\\d]+',s) }\n",
    "\n",
    "def add_missing_to_dict(missing_dict, tdict):\n",
    "    return {**tdict, **{ s:s for s in missing_dict}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def translate_pot(template, dest, tfunc, sources=[]):\n",
    "    pot  = polib.pofile(template)\n",
    "\n",
    "    if os.path.exists(dest):\n",
    "        po  = polib.pofile(dest)\n",
    "    else:\n",
    "        po = polib.POFile()\n",
    "        po.metadata = pot.metadata\n",
    "\n",
    "    todo = { (entry.msgctx,entry.msgid) for entry in pot }\n",
    "    existing = { (entry.msgctx,entry.msgid) for entry in po }\n",
    "\n",
    "    from tqdm import tqdm\n",
    "\n",
    "    # Go through sources and add translations found there to the pot\n",
    "    if sources:\n",
    "        n_existing = len(existing)\n",
    "        for source in tqdm(sources,desc='Checking existing translations'):\n",
    "            spo = polib.pofile(source)\n",
    "            for entry in spo:\n",
    "                if (entry.msgctx,entry.msgid) not in todo: continue\n",
    "                if (entry.msgctx,entry.msgid) in existing: continue\n",
    "                \n",
    "                if entry.msgstr: entry.msgstr = tfunc(entry.msgstr)\n",
    "                po.append(entry)\n",
    "                existing.add((entry.msgctx,entry.msgid))\n",
    "\n",
    "        n_found = len(existing) - n_existing\n",
    "        if n_found: print(f'Found {n_found} translations in {sources}')\n",
    "\n",
    "    n = len(pot) - len(existing)\n",
    "    progress = tqdm(pot,desc='Translating',total=n)\n",
    "\n",
    "    for entry in pot:\n",
    "        if (entry.msgctx,entry.msgid) in existing: continue\n",
    "\n",
    "        if not entry.msgstr: continue\n",
    "        entry.msgstr = t_func(entry.msgstr)\n",
    "        po.append(entry)\n",
    "\n",
    "        progress.update(1)\n",
    "\n",
    "    progress.close()\n",
    "\n",
    "    po.save(dest)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup guide\n",
    "- User conf\n",
    "  - cookie key matters. generate a decent one random\n",
    "- Logfile - make sure to touch a local one so local logs don't pollute the deploy\n",
    "- Files: if deploy.json targets missing, notify. If files not present in s3, copy over. Add flag to have them updated\n",
    "- Translations: keep in repo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot export to html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "\n",
    "# This is the default theme for Streamlit (v1.42.1)\n",
    "# We want to match it in our exports\n",
    "altair_default_config = {\n",
    "    \"font\": \"\\\"Source Sans Pro\\\", sans-serif\",\n",
    "    \"background\": \"#ffffff\",\n",
    "    \"fieldTitle\": \"verbal\",\n",
    "    \"autosize\": {\"type\": \"fit\", \"contains\": \"padding\"},\n",
    "    \"title\": {\n",
    "      \"align\": \"left\",\n",
    "      \"anchor\": \"start\",\n",
    "      \"color\": \"#31333F\",\n",
    "      \"titleFontStyle\": \"normal\",\n",
    "      \"fontWeight\": 600,\n",
    "      \"fontSize\": 16,\n",
    "      \"orient\": \"top\",\n",
    "      \"offset\": 26\n",
    "    },\n",
    "    \"header\": {\n",
    "      \"titleFontWeight\": 400,\n",
    "      \"titleFontSize\": 16,\n",
    "      \"titleColor\": \"#808495\",\n",
    "      \"titleFontStyle\": \"normal\",\n",
    "      \"labelFontSize\": 12,\n",
    "      \"labelFontWeight\": 400,\n",
    "      \"labelColor\": \"#808495\",\n",
    "      \"labelFontStyle\": \"normal\"\n",
    "    },\n",
    "    \"axis\": {\n",
    "      \"labelFontSize\": 12,\n",
    "      \"labelFontWeight\": 400,\n",
    "      \"labelColor\": \"#808495\",\n",
    "      \"labelFontStyle\": \"normal\",\n",
    "      \"titleFontWeight\": 400,\n",
    "      \"titleFontSize\": 14,\n",
    "      \"titleColor\": \"#808495\",\n",
    "      \"titleFontStyle\": \"normal\",\n",
    "      \"ticks\": False,\n",
    "      \"gridColor\": \"#e6eaf1\",\n",
    "      \"domain\": False,\n",
    "      \"domainWidth\": 1,\n",
    "      \"domainColor\": \"#e6eaf1\",\n",
    "      \"labelFlush\": True,\n",
    "      \"labelFlushOffset\": 1,\n",
    "      \"labelBound\": False,\n",
    "      \"labelLimit\": 100,\n",
    "      \"titlePadding\": 16,\n",
    "      \"labelPadding\": 16,\n",
    "      \"labelSeparation\": 4,\n",
    "      \"labelOverlap\": True\n",
    "    },\n",
    "    \"legend\": {\n",
    "      \"labelFontSize\": 14,\n",
    "      \"labelFontWeight\": 400,\n",
    "      \"labelColor\": \"#808495\",\n",
    "      \"titleFontSize\": 14,\n",
    "      \"titleFontWeight\": 400,\n",
    "      \"titleFontStyle\": \"normal\",\n",
    "      \"titleColor\": \"#808495\",\n",
    "      \"titlePadding\": 5,\n",
    "      \"labelPadding\": 16,\n",
    "      \"columnPadding\": 8,\n",
    "      \"rowPadding\": 4,\n",
    "      \"padding\": 7,\n",
    "      \"symbolStrokeWidth\": 4\n",
    "    },\n",
    "    \"range\": {\n",
    "      \"category\": [\n",
    "        \"#0068c9\",\n",
    "        \"#83c9ff\",\n",
    "        \"#ff2b2b\",\n",
    "        \"#ffabab\",\n",
    "        \"#29b09d\",\n",
    "        \"#7defa1\",\n",
    "        \"#ff8700\",\n",
    "        \"#ffd16a\",\n",
    "        \"#6d3fc0\",\n",
    "        \"#d5dae5\"\n",
    "      ],\n",
    "      \"diverging\": [\n",
    "        \"#7d353b\",\n",
    "        \"#bd4043\",\n",
    "        \"#ff4b4b\",\n",
    "        \"#ff8c8c\",\n",
    "        \"#ffc7c7\",\n",
    "        \"#a6dcff\",\n",
    "        \"#60b4ff\",\n",
    "        \"#1c83e1\",\n",
    "        \"#0054a3\",\n",
    "        \"#004280\"\n",
    "      ],\n",
    "      \"ramp\": [\n",
    "        \"#e4f5ff\",\n",
    "        \"#c7ebff\",\n",
    "        \"#a6dcff\",\n",
    "        \"#83c9ff\",\n",
    "        \"#60b4ff\",\n",
    "        \"#3d9df3\",\n",
    "        \"#1c83e1\",\n",
    "        \"#0068c9\",\n",
    "        \"#0054a3\",\n",
    "        \"#004280\"\n",
    "      ],\n",
    "      \"heatmap\": [\n",
    "        \"#e4f5ff\",\n",
    "        \"#c7ebff\",\n",
    "        \"#a6dcff\",\n",
    "        \"#83c9ff\",\n",
    "        \"#60b4ff\",\n",
    "        \"#3d9df3\",\n",
    "        \"#1c83e1\",\n",
    "        \"#0068c9\",\n",
    "        \"#0054a3\",\n",
    "        \"#004280\"\n",
    "      ]\n",
    "    },\n",
    "    \"view\": {\n",
    "      \"columns\": 1,\n",
    "      \"strokeWidth\": 0,\n",
    "      \"stroke\": \"transparent\",\n",
    "      \"continuousHeight\": 350,\n",
    "      \"continuousWidth\": 400,\n",
    "      \"discreteHeight\": {\"step\": 20}\n",
    "    },\n",
    "    \"concat\": {\"columns\": 1},\n",
    "    \"facet\": {\"columns\": 1},\n",
    "    \"mark\": {\"tooltip\": True, \"color\": \"#0068c9\"},\n",
    "    \"bar\": {\"binSpacing\": 4, \"discreteBandSize\": {\"band\": 0.85}},\n",
    "    \"axisDiscrete\": {\"grid\": False},\n",
    "    \"axisXPoint\": {\"grid\": False},\n",
    "    \"axisTemporal\": {\"grid\": False},\n",
    "    \"axisXBand\": {\"grid\": False}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "# Create an HTML of a matrix of plots\n",
    "# Based on what altair plot.save('plot.html') does, but modified to draw a full matrix and autoresize\n",
    "def plot_matrix_html(pmat, uid='viz', width=None, responsive=True):\n",
    "    if not pmat: return\n",
    "    if not isinstance(pmat,list): pmat, ucw = [[pmat]], False\n",
    "\n",
    "    template = '''\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head></head>\n",
    "<body>\n",
    "  <div id=\"UID\">SUBDIVS</div>\n",
    "  <script src=\"https://cdn.jsdelivr.net/npm/vega@5\"></script>\n",
    "  <script src=\"https://cdn.jsdelivr.net/npm/vega-lite@5\"></script>\n",
    "  <script src=\"https://cdn.jsdelivr.net/npm/vega-embed@6\"></script>\n",
    "  <script type=\"text/javascript\">\n",
    "    UID_delta = 0\n",
    "    function draw_plot() {\n",
    "        width = document.getElementById(\"UID\").parentElement.clientWidth;\n",
    "        var specs = %s;\n",
    "        var opt = {\"renderer\": \"canvas\", \"actions\": false};\n",
    "        specs.forEach(function(spec,i){ vegaEmbed(\"#UID-\"+i, spec, opt); });\n",
    "    };\n",
    "    draw_plot();\n",
    "    // This is a hack to fix facet plot width issues\n",
    "    setTimeout(function() {\n",
    "        wc = %s;\n",
    "        wp = document.getElementById(\"UID\").offsetWidth;\n",
    "        UID_delta = wp-wc;\n",
    "        if (UID_delta!=0) draw_plot();\n",
    "    }, 5);\n",
    "    %s\n",
    "  </script>\n",
    "</body>\n",
    "</html>\n",
    "'''.replace('UID',uid)\n",
    "\n",
    "    rstring = 'XYZresponsiveXZY' # Something we can replace easy\n",
    "    specs, ncols = [], len(pmat[0])\n",
    "    for i,p in enumerate(pmat):\n",
    "        for j, pp in enumerate(p):\n",
    "            pdict = json.loads(pp.to_json())\n",
    "            pdict['autosize'] = {'type': 'fit', 'contains': 'padding'}\n",
    "            pdict['config'] = altair_default_config\n",
    "            \n",
    "            if responsive:\n",
    "                cwidth = pdict['spec']['width'] if 'spec' in pdict else pdict['width']\n",
    "                repl = f'(width-{uid}_delta/{ncols})/{width/cwidth}' \n",
    "                if 'spec' in pdict: pdict['spec']['width'] = rstring\n",
    "                else: pdict['width'] = rstring\n",
    "                pjson = json.dumps(pdict).replace(f'\"{rstring}\"', repl)\n",
    "            else: pjson = json.dumps(pdict)\n",
    "            specs.append(pjson)\n",
    "\n",
    "    if responsive: \n",
    "        goal_width = f'document.getElementById(\"{uid}\").parentElement.clientWidth'\n",
    "        resp_code = 'window.addEventListener(\"resize\", draw_plot);'\n",
    "    else: goal_width, resp_code = str(width), '';\n",
    "\n",
    "    html = template % (f'[{\",\".join(specs)}]',goal_width,resp_code)\n",
    "\n",
    "    # Add subdivs after the plots - otherwise width% needs complex escaping\n",
    "    subdivs = ''.join([f'<div id=\"{uid}-{i}\" styles=\"width: {0.99/ncols:.3}%\"></div>' for i in range(sum(map(len,pmat)))])\n",
    "    html = html.replace('SUBDIVS',subdivs)\n",
    "\n",
    "    if responsive: html = html.replace(f'\"{rstring}\"', repl)\n",
    "    return html\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "salk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
